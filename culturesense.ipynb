{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# CultureSense \u2014 Longitudinal Clinical Hypothesis Engine\n## Kaggle HAI-DEF Competition Submission\n\n[![MedGemma](https://img.shields.io/badge/MedGemma-4b--it-blue)](https://huggingface.co/google/medgemma-4b-it)\n[![Safety](https://img.shields.io/badge/Safety-Non--Diagnostic-green)]()\n[![Mode](https://img.shields.io/badge/Mode-Patient%20%2B%20Clinician-purple)]()\n\n> **CultureSense** processes 2\u20133 sequential urine or stool culture lab reports and produces\n> structured, **non-diagnostic** interpretations through two distinct output modes.\n> MedGemma handles natural language generation from already-structured inputs.\n> Deterministic rules handle all temporal signal extraction.\n\n---\n\n## Architecture\n\n```mermaid\nflowchart TD\n    A[\"[1] Raw Report Ingestion\\nList[str] 2-3 free-text culture reports\"] --> B\n    B[\"[2] Structured Extraction Layer\\nextract_structured_data() \u2192 CultureReport\"] --> C\n    C[\"[3] Temporal Comparison Engine\\nanalyze_trend() \u2192 TrendResult\"] --> D\n    D[\"[4] Hypothesis Update Layer\\ngenerate_hypothesis() \u2192 HypothesisResult\\nconfidence [0.0\u20130.95]\"] --> E\n    E[\"[5] MedGemma Reasoning Layer\\ncall_medgemma(structured_payload, mode) \u2192 str\\nModes: patient | clinician\"] --> F\n    F[\"[6] Structured Safe Output Renderer\\nrender_output() \u2192 FormattedOutput\\nPatient: explanation + questions\\nClinician: trajectory + confidence + flags\"]\n\n    style A fill:#e8f4f8\n    style B fill:#d4edda\n    style C fill:#d4edda\n    style D fill:#fff3cd\n    style E fill:#f8d7da\n    style F fill:#e8f4f8\n```\n\n**Key safety invariant:** Raw report text is NEVER forwarded to MedGemma.\nOnly derived structured fields (typed dataclasses \u2192 JSON) are passed to the model.\n\n---\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell A: Setup & Imports"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell A-1: Repository Setup (for Colab/Kaggle)\nimport os\nif not os.path.exists('culturesense'):\n    !git clone https://github.com/shuknuk/culturesense.git\n    %cd culturesense\nelse:\n    print(\"Repository 'culturesense' already exists.\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell A-2: Library Installation\nimport subprocess, sys\n\npackages = [\n    \"transformers>=4.40.0\",\n    \"accelerate>=0.29.0\",\n    \"sentencepiece>=0.1.99\",\n    \"huggingface_hub>=0.22.0\",\n    \"docling\",\n]\n\nfor pkg in packages:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n\nprint(\"Installation complete.\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell A-3: Core Imports\nfrom __future__ import annotations\nimport re, json, warnings\nfrom dataclasses import dataclass, field, asdict\nfrom typing import List, Dict, Optional, Tuple\n\ntry:\n    import torch\n    from transformers import AutoTokenizer, AutoModelForCausalLM\n    TRANSFORMERS_AVAILABLE = True\nexcept ImportError:\n    TRANSFORMERS_AVAILABLE = False\n    print(\"transformers not available \u2014 stub mode will be used.\")\n\nprint(\"Imports complete.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell B: Data Models & Rule Library"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional, Dict\n\n\n@dataclass\nclass CultureReport:\n    \"\"\"\n    Structured representation of a single culture lab report.\n\n    Fields:\n        date: ISO 8601 formatted date string (YYYY-MM-DD)\n        organism: Name of identified organism (e.g., \"E. coli\")\n        cfu: Colony Forming Units per mL\n        resistance_markers: List of resistance markers (subset of [\"ESBL\",\"CRE\",\"MRSA\",\"VRE\",\"CRKP\"])\n        specimen_type: Type of specimen (\"urine\" | \"stool\" | \"unknown\")\n        contamination_flag: True if organism matches contamination terms\n        raw_text: Original report string (NEVER passed to LLM)\n    \"\"\"\n\n    date: str\n    organism: str\n    cfu: int\n    resistance_markers: List[str]\n    specimen_type: str\n    contamination_flag: bool\n    raw_text: str\n\n\n@dataclass\nclass TrendResult:\n    \"\"\"\n    Temporal comparison analysis across multiple culture reports.\n\n    Fields:\n        cfu_trend: \"decreasing\" | \"increasing\" | \"fluctuating\" | \"cleared\" | \"insufficient_data\"\n        cfu_values: Ordered list of CFU values across reports\n        cfu_deltas: Per-interval changes in CFU\n        organism_persistent: True if same organism across all reports\n        organism_list: Organism name per report\n        resistance_evolution: True if new markers appear in later reports\n        resistance_timeline: Resistance markers per report\n        report_dates: ISO dates in sorted order\n        any_contamination: True if any report flagged as contamination\n    \"\"\"\n\n    cfu_trend: str\n    cfu_values: List[int]\n    cfu_deltas: List[int]\n    organism_persistent: bool\n    organism_list: List[str]\n    resistance_evolution: bool\n    resistance_timeline: List[List[str]]\n    report_dates: List[str]\n    any_contamination: bool\n\n\n@dataclass\nclass HypothesisResult:\n    \"\"\"\n    Rule-generated hypothesis with confidence scoring.\n\n    Fields:\n        interpretation: Natural language pattern summary (rule-generated)\n        confidence: Confidence score [0.0, 0.95] - never 1.0\n        risk_flags: List of risk flags (e.g., [\"EMERGING_RESISTANCE\", \"CONTAMINATION\"])\n        stewardship_alert: True if resistance_evolution is True\n        requires_clinician_review: Always True - structural safety guarantee\n    \"\"\"\n\n    interpretation: str\n    confidence: float\n    risk_flags: List[str]\n    stewardship_alert: bool\n    requires_clinician_review: bool = True\n\n\n@dataclass\nclass MedGemmaPayload:\n    \"\"\"\n    Structured payload for MedGemma model inference.\n\n    CRITICAL: raw_text from CultureReport is NEVER included in this payload.\n    Only derived structured fields are forwarded.\n\n    Fields:\n        mode: \"patient\" | \"clinician\"\n        trend_summary: Serialized TrendResult\n        hypothesis_summary: Serialized HypothesisResult\n        safety_constraints: Injected safety instructions\n        output_schema: Expected output fields for this mode\n    \"\"\"\n\n    mode: str\n    trend_summary: dict\n    hypothesis_summary: dict\n    safety_constraints: List[str]\n    output_schema: dict\n\n\n@dataclass\nclass FormattedOutput:\n    \"\"\"\n    Final rendered output for either Patient or Clinician mode.\n\n    Fields are mode-specific. Patient mode uses patient_* fields,\n    Clinician mode uses clinician_* fields.\n    \"\"\"\n\n    mode: str\n\n    # Patient mode fields\n    patient_explanation: Optional[str] = None\n    patient_trend_phrase: Optional[str] = None\n    patient_questions: Optional[List[str]] = None\n    patient_disclaimer: str = \"\"\n\n    # Clinician mode fields\n    clinician_trajectory: Optional[dict] = None\n    clinician_interpretation: Optional[str] = None\n    clinician_confidence: Optional[float] = None\n    clinician_resistance_detail: Optional[str] = None\n    clinician_stewardship_flag: Optional[bool] = None\n    clinician_disclaimer: str = \"\""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# ---------------------------------------------------------------------------\n# Core clinical rules and thresholds\n# ---------------------------------------------------------------------------\nRULES = {\n    # CFU/mL threshold above which a urine specimen is considered infected\n    \"infection_threshold_urine\": 100000,\n    # CFU/mL threshold above which a stool specimen is considered infected\n    \"infection_threshold_stool\": 50000,\n    # A reduction of 75%+ from the previous reading is a strong improvement\n    \"significant_reduction_pct\": 0.75,\n    # Organism names indicating sample contamination rather than true infection\n    \"contamination_terms\": [\n        \"mixed flora\",\n        \"skin flora\",\n        \"normal flora\",\n        \"commensal\",\n        \"contamination\",\n        \"mixed growth\",\n    ],\n    # High-risk resistance markers tracked by the rule engine\n    \"high_risk_markers\": [\"ESBL\", \"CRE\", \"MRSA\", \"VRE\", \"CRKP\"],\n    # CFU/mL at or below this value is treated as effectively cleared\n    \"cleared_threshold\": 1000,\n    # Hard ceiling on confidence - epistemic humility; never 1.0\n    \"max_confidence\": 0.95,\n    # Starting confidence before any signal adjustments\n    \"base_confidence\": 0.50,\n}\n\n# ---------------------------------------------------------------------------\n# Organism alias normalisation lookup table\n# Maps common shorthand/abbreviations \u2192 canonical organism name.\n# Matching is performed case-insensitively against stripped input.\n# ---------------------------------------------------------------------------\nORGANISM_ALIASES: dict = {\n    # Escherichia coli variants\n    \"e. coli\": \"Escherichia coli\",\n    \"e.coli\": \"Escherichia coli\",\n    \"e coli\": \"Escherichia coli\",\n    \"escherichia coli\": \"Escherichia coli\",\n    # Klebsiella\n    \"klebsiella\": \"Klebsiella pneumoniae\",\n    \"klebsiella pneumoniae\": \"Klebsiella pneumoniae\",\n    # Staphylococcus\n    \"staph aureus\": \"Staphylococcus aureus\",\n    \"staphylococcus aureus\": \"Staphylococcus aureus\",\n    \"s. aureus\": \"Staphylococcus aureus\",\n    \"mrsa\": \"Staphylococcus aureus (MRSA)\",\n    # Enterococcus\n    \"enterococcus\": \"Enterococcus faecalis\",\n    \"enterococcus faecalis\": \"Enterococcus faecalis\",\n    \"e. faecalis\": \"Enterococcus faecalis\",\n    # Pseudomonas\n    \"pseudomonas\": \"Pseudomonas aeruginosa\",\n    \"pseudomonas aeruginosa\": \"Pseudomonas aeruginosa\",\n    \"p. aeruginosa\": \"Pseudomonas aeruginosa\",\n    # Proteus\n    \"proteus\": \"Proteus mirabilis\",\n    \"proteus mirabilis\": \"Proteus mirabilis\",\n    # Contamination terms (kept as-is but included for normalisation completeness)\n    \"mixed flora\": \"mixed flora\",\n    \"skin flora\": \"skin flora\",\n    \"normal flora\": \"normal flora\",\n    \"commensal\": \"commensal\",\n    \"mixed growth\": \"mixed growth\",\n}\n\n\ndef normalize_organism(raw: str) -> str:\n    \"\"\"\n    Normalise a raw organism string to its canonical name.\n\n    Performs case-insensitive lookup against ORGANISM_ALIASES.\n    Returns the canonical name if found, otherwise returns the stripped\n    title-cased version of the original input.\n\n    Args:\n        raw: Raw organism string from extraction layer.\n\n    Returns:\n        Canonical organism name string.\n    \"\"\"\n    key = raw.strip().lower()\n    return ORGANISM_ALIASES.get(key, raw.strip())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell C: Extraction Layer"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nimport re\nimport tempfile\nimport warnings\nfrom pathlib import Path\nfrom typing import Optional\n\n\n\n# ---------------------------------------------------------------------------\n# Helper: Docling Processing\n# ---------------------------------------------------------------------------\ndef _process_with_docling(input_text: str) -> str:\n    \"\"\"\n    Process input text using Docling.\n\n    If input_text is a valid file path, processes that file.\n    Otherwise, writes text to a temporary file and processes it.\n    Returns the structured markdown text from the document.\n    \"\"\"\n    try:\n        from docling.document_converter import DocumentConverter\n    except ImportError:\n        # Silently fail or log debug if needed, but for user-facing, return original text\n        # Only warn once if desired, but here we just return\n        return input_text\n\n    input_path = Path(input_text)\n    is_file = input_path.exists() and input_path.is_file()\n\n    try:\n        converter = DocumentConverter()\n\n        if is_file:\n            # Process directly from file path\n            result = converter.convert(input_path)\n            return result.document.export_to_markdown()\n        else:\n            # Input is raw text; Docling processing via temp file may distort layout (e.g. merging lines).\n            # Fallback to returning raw text so regexes can use original newlines.\n            return input_text\n\n    except Exception as e:\n        warnings.warn(\n            f\"Docling processing failed: {e}. Falling back to raw text.\", UserWarning\n        )\n        return input_text\n\n\n# ---------------------------------------------------------------------------\n# Custom exception\n# ---------------------------------------------------------------------------\nclass ExtractionError(ValueError):\n    \"\"\"Raised when both organism AND cfu fail to parse from a report.\"\"\"\n\n\n# ---------------------------------------------------------------------------\n# Compiled regex patterns (Section 5.2) - ENHANCED for flexibility\n# ---------------------------------------------------------------------------\n\n# Organism: Multiple patterns to handle various lab report formats\n# Fixed: Use greedy match that captures until newline but handles dots in names like \"E. coli\"\n_RE_ORGANISM_PRIMARY = re.compile(r\"Organism:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE)\n_RE_ORGANISM_ALT1 = re.compile(\n    r\"Organism\\s+identified:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE\n)\n_RE_ORGANISM_ALT2 = re.compile(r\"Isolated:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE)\n_RE_ORGANISM_ALT3 = re.compile(r\"Identification:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE)\n_RE_ORGANISM_ALT4 = re.compile(\n    r\"Culture\\s+results?:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE\n)\n_RE_ORGANISM_ALT5 = re.compile(r\"ORGANISM:\\s*([^.].*?)(?:\\n|$)\", re.IGNORECASE)\n\n# CFU/mL: Multiple patterns for various formats\n_RE_CFU_PRIMARY = re.compile(r\"CFU[/\\\\]?m?L?:\\s*([><]?\\s*[\\d,]+)\", re.IGNORECASE)\n_RE_CFU_ALT1 = re.compile(\n    r\"(?:Count|Quantity|Result):\\s*([><]?\\s*[\\d,]+)\", re.IGNORECASE\n)\n_RE_CFU_ALT2 = re.compile(r\"([\\d,]+)\\s*(?:CFU|colonies|cells)\", re.IGNORECASE)\n_RE_CFU_ALT3 = re.compile(r\">\\s*?([\\d,]+)\", re.IGNORECASE)  # >100,000\n_RE_CFU_ALT4 = re.compile(r\"(\\d{2,3},\\d{3})\", re.IGNORECASE)  # 100,000 pattern\n\n# Fallback CFU patterns\n_RE_CFU_SCIENTIFIC = re.compile(r\"10\\^(\\d+)\", re.IGNORECASE)  # 10^5 \u2192 100000\n_RE_CFU_WORD = re.compile(r\"(TNTC|Too\\s+Numerous\\s+To\\s+Count)\", re.IGNORECASE)\n_RE_CFU_NO_GROWTH = re.compile(\n    r\"(No\\s+growth|No\\s+significant\\s+growth|0\\s+CFU|Negative)\", re.IGNORECASE\n)\n_RE_CFU_RAW_NUMBER = re.compile(r\"\\b([\\d]{5,})\\b\")  # bare large number (5+ digits)\n\n# Date: Multiple patterns for various formats\n_RE_DATE_PRIMARY = re.compile(\n    r\"(?:Date|Collected|Reported|Specimen\\s+Date|Collection\\s+Date|Date\\s+Collected|Date\\s+Reported)[\\s:]*[\\*_]*[\\s:]+(\\d{4}-\\d{2}-\\d{2}|\\d{2}/\\d{2}/\\d{4}|\\d{2}-\\d{2}-\\d{4})\",\n    re.IGNORECASE,\n)\n_RE_DATE_ALT1 = re.compile(r\"\\b(\\d{4}-\\d{2}-\\d{2})\\b\")  # ISO format anywhere\n_RE_DATE_ALT2 = re.compile(r\"\\b(\\d{2}/\\d{2}/\\d{4})\\b\")  # MM/DD/YYYY anywhere\n_RE_DATE_ALT3 = re.compile(r\"\\b(\\d{2}-\\d{2}-\\d{4})\\b\")  # MM-DD-YYYY anywhere\n\n# Resistance markers: exact case-insensitive word boundaries\n_RE_RESISTANCE = re.compile(r\"\\b(ESBL|CRE|MRSA|VRE|CRKP)\\b\", re.IGNORECASE)\n\n# Specimen type - ENHANCED: multiple patterns and keyword detection\n_RE_SPECIMEN_PRIMARY = re.compile(\n    r\"(?:Specimen|Sample|Source|Type)[\\s:]+(urine|stool|wound|blood|urinary|fecal|faecal)\",\n    re.IGNORECASE,\n)\n_RE_SPECIMEN_ALT1 = re.compile(\n    r\"(urine|stool|wound|blood)\\s*(?:culture|specimen|sample|test)\", re.IGNORECASE\n)\n_RE_SPECIMEN_ALT2 = re.compile(\n    r\"(?:culture|specimen|sample|test)\\s*(?:type)?[\\s:]+(urine|stool|wound|blood)\",\n    re.IGNORECASE,\n)\n# Match markdown headers and bold text: ## Urine Culture, **Urine Culture**, Urine Culture\n_RE_SPECIMEN_HEADER = re.compile(\n    r\"(?:^#{1,3}\\s*|\\*{2}|\\_{2}|##\\s*)\\s*(urine|stool|wound|blood|sputum)\\s+culture\\b\",\n    re.IGNORECASE | re.MULTILINE,\n)\n_RE_SPECIMEN_URINE_KEYWORD = re.compile(\n    r\"\\b(urine|urinary|bladder|catheter)\\b\", re.IGNORECASE\n)\n_RE_SPECIMEN_STOOL_KEYWORD = re.compile(\n    r\"\\b(stool|fecal|faecal|feces|gi)\\b\", re.IGNORECASE\n)\n\n\n# ---------------------------------------------------------------------------\n# CFU normalisation helper (Section 5.4) - ENHANCED\n# ---------------------------------------------------------------------------\n\n\ndef _parse_cfu(report_text: str) -> tuple[int, bool]:\n    \"\"\"\n    Attempt to parse the CFU/mL value from a report text string.\n\n    Returns:\n        (cfu_value, parse_success) tuple.\n\n    Normalisation rules:\n        - \"TNTC\" / \"Too Numerous To Count\" \u2192 999999\n        - \"No growth\" / \"0 CFU\"            \u2192 0\n        - \"10^5\"                            \u2192 100000\n        - \">100,000\" or \"> 100,000\"         \u2192 100000 (or parse the number)\n        - comma-separated integer           \u2192 int (commas stripped)\n        - Missing/unparseable               \u2192 0 with warning\n    \"\"\"\n    text = report_text.strip()\n\n    # 1. Primary: \"CFU/mL: 120,000\" or \"CFU/mL: >100,000\"\n    m = _RE_CFU_PRIMARY.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\").replace(\">\", \"\").replace(\"<\", \"\").strip()\n        try:\n            return int(raw), True\n        except ValueError:\n            pass\n\n    # 2. Alternative: \"Count: 120,000\" or \"Result: >100,000\"\n    m = _RE_CFU_ALT1.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\").replace(\">\", \"\").replace(\"<\", \"\").strip()\n        try:\n            return int(raw), True\n        except ValueError:\n            pass\n\n    # 3. Alternative: \"120,000 CFU\" or \"120,000 colonies\"\n    m = _RE_CFU_ALT2.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\")\n        try:\n            return int(raw), True\n        except ValueError:\n            pass\n\n    # 4. Alternative: \">100,000\" or \"> 100,000\"\n    m = _RE_CFU_ALT3.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\")\n        try:\n            return int(raw), True\n        except ValueError:\n            pass\n\n    # 5. Alternative: standalone 100,000 pattern\n    m = _RE_CFU_ALT4.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\")\n        try:\n            return int(raw), True\n        except ValueError:\n            pass\n\n    # 6. TNTC\n    if _RE_CFU_WORD.search(text):\n        return 999999, True\n\n    # 7. No growth / negative\n    if _RE_CFU_NO_GROWTH.search(text):\n        return 0, True\n\n    # 8. Scientific notation \"10^5\"\n    m = _RE_CFU_SCIENTIFIC.search(text)\n    if m:\n        try:\n            return 10 ** int(m.group(1)), True\n        except (ValueError, OverflowError):\n            pass\n\n    # 9. Bare large integer (\u22655 digits) \u2014 last resort fallback\n    m = _RE_CFU_RAW_NUMBER.search(text)\n    if m:\n        raw = m.group(1).replace(\",\", \"\")\n        try:\n            val = int(raw)\n            warnings.warn(\n                f\"CFU parsed from bare number '{raw}' \u2014 review report text.\",\n                UserWarning,\n                stacklevel=3,\n            )\n            return val, True\n        except ValueError:\n            pass\n\n    warnings.warn(\n        \"CFU/mL could not be parsed; defaulting to 0.\", UserWarning, stacklevel=3\n    )\n    return 0, False\n\n\ndef _parse_date(report_text: str) -> str:\n    \"\"\"Extract and normalise the collection date from report text.\"\"\"\n    # Primary: prefixed dates\n    m = _RE_DATE_PRIMARY.search(report_text)\n    if m:\n        raw = m.group(1)\n        return _normalize_date(raw)\n\n    # Alt1: ISO format anywhere\n    m = _RE_DATE_ALT1.search(report_text)\n    if m:\n        return m.group(1)\n\n    # Alt2: MM/DD/YYYY anywhere\n    m = _RE_DATE_ALT2.search(report_text)\n    if m:\n        return _normalize_date(m.group(1))\n\n    # Alt3: MM-DD-YYYY anywhere\n    m = _RE_DATE_ALT3.search(report_text)\n    if m:\n        raw = m.group(1).replace(\"-\", \"/\")\n        return _normalize_date(raw)\n\n    return \"unknown\"\n\n\ndef _normalize_date(raw: str) -> str:\n    \"\"\"Convert various date formats to ISO 8601 (YYYY-MM-DD).\"\"\"\n    raw = raw.strip()\n\n    # Already ISO format\n    if re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", raw):\n        return raw\n\n    # MM/DD/YYYY or MM-DD-YYYY\n    if \"/\" in raw or \"-\" in raw:\n        sep = \"/\" if \"/\" in raw else \"-\"\n        parts = raw.split(sep)\n        if len(parts) == 3:\n            # Determine if first part is month or day based on values\n            first, second, year = parts[0], parts[1], parts[2]\n            # If first > 12, it's likely DD/MM/YYYY\n            if int(first) > 12:\n                # DD/MM/YYYY \u2192 YYYY-MM-DD\n                return f\"{year}-{second.zfill(2)}-{first.zfill(2)}\"\n            else:\n                # MM/DD/YYYY \u2192 YYYY-MM-DD\n                return f\"{year}-{first.zfill(2)}-{second.zfill(2)}\"\n\n    return \"unknown\"\n\n\ndef _parse_organism(report_text: str) -> Optional[str]:\n    \"\"\"\n    Extract organism name from report text with multiple pattern attempts.\n    \"\"\"\n    text = report_text.strip()\n\n    # Try multiple organism patterns in order\n    patterns = [\n        _RE_ORGANISM_PRIMARY,\n        _RE_ORGANISM_ALT5,  # ORGANISM: (all caps)\n        _RE_ORGANISM_ALT1,  # Organism identified:\n        _RE_ORGANISM_ALT2,  # Isolated:\n        _RE_ORGANISM_ALT3,  # Identification:\n        _RE_ORGANISM_ALT4,  # Culture result:\n    ]\n\n    for pattern in patterns:\n        m = pattern.search(text)\n        if m:\n            raw_organism = m.group(1).strip()\n            # Clean up common artifacts but preserve dots in organism names like \"E. coli\"\n            raw_organism = re.sub(r\"\\s+\", \" \", raw_organism)  # normalize whitespace\n            # Don't split on dots - they're part of organism names like \"E. coli\"\n            # Only truncate if there's clear sentence-ending punctuation\n            if re.search(r\"[;!?]|\\.\\s+[A-Z]\", raw_organism):\n                # Find the first sentence-ending punctuation\n                match = re.search(r\"([;!?]|\\.\\s+[A-Z])\", raw_organism)\n                if match:\n                    raw_organism = raw_organism[: match.start()]\n            return normalize_organism(raw_organism)\n\n    # Fallback: search for known organism aliases in full text\n    lower_text = text.lower()\n\n    for alias in sorted(ORGANISM_ALIASES.keys(), key=len, reverse=True):\n        if alias in lower_text:\n            return normalize_organism(alias)\n\n    return None\n\n\ndef _parse_resistance_markers(report_text: str) -> list[str]:\n    \"\"\"Extract all high-risk resistance markers (deduplicated, uppercase).\"\"\"\n    found = _RE_RESISTANCE.findall(report_text)\n    # deduplicate, preserve order\n    return list(dict.fromkeys(m.upper() for m in found))\n\n\ndef _parse_specimen(report_text: str) -> str:\n    \"\"\"\n    Extract specimen type with multiple pattern attempts and keyword detection.\n    Returns 'urine', 'stool', 'wound', 'blood', or 'unknown'.\n    \"\"\"\n    text = report_text.strip()\n\n    # Try markdown headers and bold text: ## Urine Culture, **Urine Culture**\n    m = _RE_SPECIMEN_HEADER.search(text)\n    if m:\n        return _normalize_specimen(m.group(1).lower())\n\n    # Try primary pattern: Specimen/Sample/Source/Type: urine/stool\n    m = _RE_SPECIMEN_PRIMARY.search(text)\n    if m:\n        specimen = m.group(1).lower()\n        return _normalize_specimen(specimen)\n\n    # Try alternative: urine/stool culture\n    m = _RE_SPECIMEN_ALT1.search(text)\n    if m:\n        return _normalize_specimen(m.group(1).lower())\n\n    # Try alternative: culture: urine/stool\n    m = _RE_SPECIMEN_ALT2.search(text)\n    if m:\n        return _normalize_specimen(m.group(1).lower())\n\n    # Keyword detection: look for urine/urinary keywords anywhere\n    if _RE_SPECIMEN_URINE_KEYWORD.search(text):\n        return \"urine\"\n\n    # Keyword detection: look for stool/fecal keywords anywhere\n    if _RE_SPECIMEN_STOOL_KEYWORD.search(text):\n        return \"stool\"\n\n    return \"unknown\"\n\n\ndef _normalize_specimen(specimen: str) -> str:\n    \"\"\"Normalize specimen type to standard values.\"\"\"\n    specimen = specimen.lower().strip()\n\n    # Map variations to standard types\n    if specimen in (\"urine\", \"urinary\"):\n        return \"urine\"\n    elif specimen in (\"stool\", \"fecal\", \"faecal\", \"feces\"):\n        return \"stool\"\n    elif specimen == \"wound\":\n        return \"wound\"\n    elif specimen == \"blood\":\n        return \"blood\"\n\n    return specimen\n\n\ndef _is_contamination(organism: str) -> bool:\n    \"\"\"Return True if the organism name matches any contamination term.\"\"\"\n    lower = organism.lower()\n    return any(term in lower for term in RULES[\"contamination_terms\"])\n\n\n# ---------------------------------------------------------------------------\n# Debug helper\n# ---------------------------------------------------------------------------\n\n\ndef debug_extraction(report_text: str, label: str = \"Report\") -> dict:\n    \"\"\"\n    Debug helper to show what was extracted from a report.\n\n    Returns a dictionary with all extraction results for debugging.\n    \"\"\"\n    processed_text = (\n        _process_with_docling(report_text)\n        if Path(report_text).exists()\n        else report_text\n    )\n\n    organism = _parse_organism(processed_text)\n    cfu, cfu_ok = _parse_cfu(processed_text)\n    specimen = _parse_specimen(processed_text)\n    date = _parse_date(processed_text)\n    resistance = _parse_resistance_markers(processed_text)\n\n    return {\n        \"label\": label,\n        \"organism\": organism,\n        \"cfu\": cfu,\n        \"cfu_ok\": cfu_ok,\n        \"specimen\": specimen,\n        \"date\": date,\n        \"resistance\": resistance,\n        \"is_contamination\": _is_contamination(organism) if organism else False,\n        \"processed_text_preview\": processed_text[:500] + \"...\"\n        if len(processed_text) > 500\n        else processed_text,\n    }\n\n\n# ---------------------------------------------------------------------------\n# Public extraction function\n# ---------------------------------------------------------------------------\n\n\ndef extract_structured_data(report_text: str) -> CultureReport:\n    \"\"\"\n    Parse a free-text culture report into a typed CultureReport.\n\n    Now supports direct file paths via Docling processing.\n\n    Rules:\n        - Organism field: stripped, normalised via ORGANISM_ALIASES\n        - CFU: commas removed, converted to int; TNTC=999999\n        - resistance_markers: deduplicated, uppercase\n        - contamination_flag: True if organism in contamination_terms\n        - raw_text: stored as-is (or docling processed), NEVER forwarded to MedGemma\n\n    Raises:\n        ExtractionError: if both organism AND cfu fail to parse.\n    \"\"\"\n    # Pre-process with Docling (handles file paths or raw text)\n    processed_text = _process_with_docling(report_text)\n\n    # Attempt extraction on processed text\n    organism = _parse_organism(processed_text)\n    cfu, cfu_ok = _parse_cfu(processed_text)\n\n    # Fallback: if extraction failed and text was modified by Docling, try original\n    if (organism is None and not cfu_ok) and processed_text != report_text:\n        organism = _parse_organism(report_text)\n        cfu, cfu_ok = _parse_cfu(report_text)\n        if organism is not None or cfu_ok:\n            processed_text = report_text  # Revert to original for other fields\n\n    if organism is None and not cfu_ok:\n        raise ExtractionError(\n            \"Extraction failed: could not parse organism OR CFU/mL from report. \"\n            \"Check report format.\"\n        )\n\n    # If only organism failed, use a placeholder and warn\n    if organism is None:\n        warnings.warn(\n            \"Organism could not be parsed; using 'unknown'.\", UserWarning, stacklevel=2\n        )\n        organism = \"unknown\"\n\n    resistance_markers = _parse_resistance_markers(processed_text)\n    specimen_type = _parse_specimen(processed_text)\n    contamination_flag = _is_contamination(organism)\n    date = _parse_date(processed_text)\n\n    return CultureReport(\n        date=date,\n        organism=organism,\n        cfu=cfu,\n        resistance_markers=resistance_markers,\n        specimen_type=specimen_type,\n        contamination_flag=contamination_flag,\n        raw_text=processed_text,  # Store the text actually used for extraction\n    )"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# --- Extraction Unit Tests ---\n\nimport warnings\n\n\n_PASS = 0\n_FAIL = 0\n\n\ndef _assert(condition: bool, msg: str) -> None:\n    global _PASS, _FAIL\n    if condition:\n        _PASS += 1\n        print(f\"  PASS  {msg}\")\n    else:\n        _FAIL += 1\n        print(f\"  FAIL  {msg}\")\n\n\n# ---------------------------------------------------------------------------\n# Test Report 1 \u2014 Normal improving report\n# ---------------------------------------------------------------------------\nREPORT_NORMAL = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-01-01\nOrganism: E. coli\nCFU/mL: 120,000\nSensitivity: Ampicillin - Resistant, Nitrofurantoin - Sensitive\n\"\"\"\n\nprint(\"=== Test: Normal Report ===\")\nr = extract_structured_data(REPORT_NORMAL)\n_assert(r.date == \"2026-01-01\", f\"date == '2026-01-01'  (got '{r.date}')\")\n_assert(\n    r.organism == \"Escherichia coli\",\n    f\"organism normalised to 'Escherichia coli'  (got '{r.organism}')\",\n)\n_assert(r.cfu == 120000, f\"cfu == 120000  (got {r.cfu})\")\n_assert(\n    r.resistance_markers == [], f\"no resistance markers  (got {r.resistance_markers})\"\n)\n_assert(\n    r.specimen_type == \"urine\", f\"specimen_type == 'urine'  (got '{r.specimen_type}')\"\n)\n_assert(\n    r.contamination_flag is False,\n    f\"contamination_flag is False  (got {r.contamination_flag})\",\n)\n\n# ---------------------------------------------------------------------------\n# Test Report 2 \u2014 Contamination report (mixed flora, low CFU)\n# ---------------------------------------------------------------------------\nREPORT_CONTAMINATION = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-02-05\nOrganism: mixed flora\nCFU/mL: 5,000\nNo resistance markers detected.\n\"\"\"\n\nprint(\"\\n=== Test: Contamination Report ===\")\nr2 = extract_structured_data(REPORT_CONTAMINATION)\n_assert(\n    r2.contamination_flag is True,\n    f\"contamination_flag is True  (got {r2.contamination_flag})\",\n)\n_assert(\n    r2.organism == \"mixed flora\", f\"organism == 'mixed flora'  (got '{r2.organism}')\"\n)\n_assert(r2.cfu == 5000, f\"cfu == 5000  (got {r2.cfu})\")\n_assert(\n    r2.resistance_markers == [], f\"no resistance markers  (got {r2.resistance_markers})\"\n)\n\n# ---------------------------------------------------------------------------\n# Test Report 3 \u2014 Resistance-containing report (ESBL marker)\n# ---------------------------------------------------------------------------\nREPORT_RESISTANCE = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-01-20\nOrganism: Klebsiella pneumoniae\nCFU/mL: 75,000\nResistance: ESBL detected.\n\"\"\"\n\nprint(\"\\n=== Test: Resistance Report ===\")\nr3 = extract_structured_data(REPORT_RESISTANCE)\n_assert(\n    r3.organism == \"Klebsiella pneumoniae\",\n    f\"organism == 'Klebsiella pneumoniae'  (got '{r3.organism}')\",\n)\n_assert(\n    \"ESBL\" in r3.resistance_markers,\n    f\"ESBL in resistance_markers  (got {r3.resistance_markers})\",\n)\n_assert(\n    r3.contamination_flag is False,\n    f\"contamination_flag is False  (got {r3.contamination_flag})\",\n)\n_assert(r3.cfu == 75000, f\"cfu == 75000  (got {r3.cfu})\")\n\n# ---------------------------------------------------------------------------\n# Test \u2014 TNTC CFU normalisation\n# ---------------------------------------------------------------------------\nREPORT_TNTC = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-03-01\nOrganism: E. coli\nCFU/mL: TNTC\n\"\"\"\n\nprint(\"\\n=== Test: TNTC Normalisation ===\")\nr4 = extract_structured_data(REPORT_TNTC)\n_assert(r4.cfu == 999999, f\"TNTC \u2192 999999  (got {r4.cfu})\")\n\n# ---------------------------------------------------------------------------\n# Test \u2014 No growth / cleared\n# ---------------------------------------------------------------------------\nREPORT_NO_GROWTH = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-03-15\nOrganism: E. coli\nNo growth observed.\n\"\"\"\n\nprint(\"\\n=== Test: No Growth ===\")\nr5 = extract_structured_data(REPORT_NO_GROWTH)\n_assert(r5.cfu == 0, f\"No growth \u2192 cfu == 0  (got {r5.cfu})\")\n\n# ---------------------------------------------------------------------------\n# Test \u2014 ExtractionError on completely unparseable input\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: ExtractionError on bad input ===\")\ntry:\n    extract_structured_data(\"this report contains absolutely nothing useful at all\")\n    _assert(False, \"ExtractionError should have been raised\")\nexcept ExtractionError as e:\n    _assert(True, f\"ExtractionError raised correctly: {e}\")\nexcept Exception as e:\n    _assert(False, f\"Wrong exception type raised: {type(e).__name__}: {e}\")\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Adversarial: SQL injection in CFU field\n# ---------------------------------------------------------------------------\nREPORT_ADV = \"\"\"\nSpecimen: Urine\nDate Collected: 2026-04-01\nOrganism: E. coli\nCFU/mL: 100000; DROP TABLE reports\n\"\"\"\n\nprint(\"\\n=== Test: Adversarial SQL Injection in CFU ===\")\n# Should parse 100000 from the start, or fallback gracefully\ntry:\n    r6 = extract_structured_data(REPORT_ADV)\n    # The regex only captures digits+commas, so \"100000\" is parsed, the rest is ignored\n    _assert(r6.cfu == 100000, f\"cfu == 100000 (injection ignored)  (got {r6.cfu})\")\nexcept ExtractionError:\n    _assert(False, \"Should not raise ExtractionError on adversarial CFU\")\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Alternate date format MM/DD/YYYY\n# ---------------------------------------------------------------------------\nREPORT_DATE_ALT = \"\"\"\nSpecimen: Stool\nDate Collected: 01/15/2026\nOrganism: Enterococcus faecalis\nCFU/mL: 60,000\n\"\"\"\n\nprint(\"\\n=== Test: Alternate Date Format (MM/DD/YYYY) ===\")\nr7 = extract_structured_data(REPORT_DATE_ALT)\n_assert(r7.date == \"2026-01-15\", f\"date normalised to ISO  (got '{r7.date}')\")\n_assert(\n    r7.specimen_type == \"stool\", f\"specimen_type == 'stool'  (got '{r7.specimen_type}')\"\n)\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Flexible specimen detection (alternate formats)\n# ---------------------------------------------------------------------------\nREPORT_SPECIMEN_FLEX1 = \"\"\"\nURINE CULTURE\nDate: 2026-05-01\nOrganism: E. coli\nCFU/mL: 80,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Specimen Detection (Urine Culture title) ===\")\nr8 = extract_structured_data(REPORT_SPECIMEN_FLEX1)\n_assert(\n    r8.specimen_type == \"urine\",\n    f\"specimen_type detected as 'urine' from title  (got '{r8.specimen_type}')\",\n)\n\nREPORT_SPECIMEN_FLEX2 = \"\"\"\nSpecimen Type: Stool\nDate: 2026-05-10\nOrganism: mixed flora\nCFU/mL: 2,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Specimen Detection (Specimen Type: Stool) ===\")\nr9 = extract_structured_data(REPORT_SPECIMEN_FLEX2)\n_assert(\n    r9.specimen_type == \"stool\",\n    f\"specimen_type detected as 'stool'  (got '{r9.specimen_type}')\",\n)\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Flexible organism detection (alternate formats)\n# ---------------------------------------------------------------------------\nREPORT_ORG_FLEX1 = \"\"\"\nSpecimen: Urine\nDate: 2026-06-01\nORGANISM: Klebsiella pneumoniae\nCFU/mL: 50,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Organism Detection (ORGANISM: caps) ===\")\nr10 = extract_structured_data(REPORT_ORG_FLEX1)\n_assert(\n    r10.organism == \"Klebsiella pneumoniae\",\n    f\"organism detected from ORGANISM:  (got '{r10.organism}')\",\n)\n\nREPORT_ORG_FLEX2 = \"\"\"\nSpecimen: Urine\nDate: 2026-06-15\nIsolated: E. coli\nCFU/mL: 150,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Organism Detection (Isolated:) ===\")\nr11 = extract_structured_data(REPORT_ORG_FLEX2)\n_assert(\n    r11.organism == \"Escherichia coli\",\n    f\"organism detected from Isolated:  (got '{r11.organism}')\",\n)\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Flexible CFU detection (alternate formats)\n# ---------------------------------------------------------------------------\nREPORT_CFU_FLEX1 = \"\"\"\nSpecimen: Urine\nDate: 2026-07-01\nOrganism: E. coli\nResult: >100,000 CFU/mL\n\"\"\"\n\nprint(\"\\n=== Test: Flexible CFU Detection (>100,000 format) ===\")\nr12 = extract_structured_data(REPORT_CFU_FLEX1)\n_assert(\n    r12.cfu == 100000,\n    f\"cfu parsed from >100,000 format  (got {r12.cfu})\",\n)\n\nREPORT_CFU_FLEX2 = \"\"\"\nSpecimen: Urine\nDate: 2026-07-15\nOrganism: Enterococcus faecalis\nCount: 75,000 colonies per mL\n\"\"\"\n\nprint(\"\\n=== Test: Flexible CFU Detection (Count: + colonies) ===\")\nr13 = extract_structured_data(REPORT_CFU_FLEX2)\n_assert(\n    r13.cfu == 75000,\n    f\"cfu parsed from Count: format  (got {r13.cfu})\",\n)\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Flexible date detection (alternate formats)\n# ---------------------------------------------------------------------------\nREPORT_DATE_FLEX1 = \"\"\"\nSpecimen: Urine\nCollection Date: 03/25/2026\nOrganism: E. coli\nCFU/mL: 100,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Date Detection (Collection Date MM/DD/YYYY) ===\")\nr14 = extract_structured_data(REPORT_DATE_FLEX1)\n_assert(\n    r14.date == \"2026-03-25\",\n    f\"date parsed from Collection Date:  (got '{r14.date}')\",\n)\n\nREPORT_DATE_FLEX2 = \"\"\"\nSpecimen: Urine\nDate: 07-04-2026\nOrganism: E. coli\nCFU/mL: 100,000\n\"\"\"\n\nprint(\"\\n=== Test: Flexible Date Detection (MM-DD-YYYY format) ===\")\nr15 = extract_structured_data(REPORT_DATE_FLEX2)\n_assert(\n    r15.date == \"2026-07-04\",\n    f\"date parsed from MM-DD-YYYY format  (got '{r15.date}')\",\n)\n\n# ---------------------------------------------------------------------------\n# Test \u2014 Keyword-based specimen detection (no explicit Specimen: line)\n# ---------------------------------------------------------------------------\nREPORT_KEYWORD_URINE = \"\"\"\nURINE CULTURE REPORT\nPatient: John Doe\nDate: 2026-08-01\n\nMICROBIOLOGY RESULTS:\nE. coli isolated at 100,000 CFU/mL\n\"\"\"\n\nprint(\"\\n=== Test: Keyword Specimen Detection (URINE CULTURE) ===\")\nr16 = extract_structured_data(REPORT_KEYWORD_URINE)\n_assert(\n    r16.specimen_type == \"urine\",\n    f\"specimen_type detected via urine keyword  (got '{r16.specimen_type}')\",\n)\n\nREPORT_KEYWORD_STOOL = \"\"\"\nFECAL CULTURE\nPatient: Jane Smith\nDate: 2026-08-15\n\nSalmonella detected\nCFU/mL: 45,000\n\"\"\"\n\nprint(\"\\n=== Test: Keyword Specimen Detection (FECAL CULTURE) ===\")\ntry:\n    r17 = extract_structured_data(REPORT_KEYWORD_STOOL)\n    _assert(\n        r17.specimen_type == \"stool\",\n        f\"specimen_type detected via fecal keyword  (got '{r17.specimen_type}')\",\n    )\n    _assert(\n        r17.cfu == 45000,\n        f\"cfu == 45000  (got {r17.cfu})\",\n    )\nexcept ExtractionError as e:\n    _assert(False, f\"Extraction failed for stool culture test: {e}\")\n\n# ---------------------------------------------------------------------------\n# Summary\n# ---------------------------------------------------------------------------\nprint(f\"\\n{'=' * 50}\")\nprint(f\"Extraction Tests Complete: {_PASS} passed, {_FAIL} failed\")\nif _FAIL == 0:\n    print(\"ALL TESTS PASSED\")\nelse:\n    print(f\"WARNING: {_FAIL} test(s) failed \u2014 review extraction logic\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell D: Temporal Trend Engine"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom typing import List\n\n\n\n# ---------------------------------------------------------------------------\n# Internal helpers\n# ---------------------------------------------------------------------------\n\n\ndef _classify_cfu_trend(cfu_values: List[int]) -> str:\n    \"\"\"\n    Classify the CFU trajectory from an ordered list of values.\n\n    Labels (priority order):\n        \"insufficient_data\"  \u2014 fewer than 2 reports\n        \"cleared\"            \u2014 final value \u2264 cleared_threshold (overrides all)\n        \"decreasing\"         \u2014 all values monotonically decreasing\n        \"increasing\"         \u2014 all values monotonically increasing\n        \"fluctuating\"        \u2014 any other pattern\n    \"\"\"\n    if len(cfu_values) < 2:\n        return \"insufficient_data\"\n\n    # \"cleared\" overrides all other labels\n    if cfu_values[-1] <= RULES[\"cleared_threshold\"]:\n        return \"cleared\"\n\n    strictly_decreasing = all(\n        cfu_values[i] > cfu_values[i + 1] for i in range(len(cfu_values) - 1)\n    )\n    if strictly_decreasing:\n        return \"decreasing\"\n\n    strictly_increasing = all(\n        cfu_values[i] < cfu_values[i + 1] for i in range(len(cfu_values) - 1)\n    )\n    if strictly_increasing:\n        return \"increasing\"\n\n    return \"fluctuating\"\n\n\ndef _compute_deltas(cfu_values: List[int]) -> List[int]:\n    \"\"\"\n    Compute per-interval CFU changes.\n\n    Positive delta = worsening (increasing CFU).\n    Negative delta = improving (decreasing CFU).\n    \"\"\"\n    return [cfu_values[i + 1] - cfu_values[i] for i in range(len(cfu_values) - 1)]\n\n\ndef _check_persistence(organism_list: List[str]) -> bool:\n    \"\"\"\n    Return True if the same organism was isolated across all reports.\n\n    Comparison is performed on normalised (lowercase, stripped) organism names,\n    with alias resolution to handle \"E. coli\" == \"Escherichia coli\".\n    \"\"\"\n    normalised = [normalize_organism(o).strip().lower() for o in organism_list]\n    return len(set(normalised)) == 1\n\n\ndef _check_resistance_evolution(reports: List[CultureReport]) -> bool:\n    \"\"\"\n    Return True if new resistance markers appear in any report after the first.\n\n    Logic:\n        - Baseline = markers in report[0]\n        - If any subsequent report contains a marker not in baseline \u2192 True\n    \"\"\"\n    if len(reports) < 2:\n        return False\n    baseline = set(reports[0].resistance_markers)\n    later_markers: set[str] = set()\n    for r in reports[1:]:\n        later_markers.update(r.resistance_markers)\n    return bool(later_markers - baseline)\n\n\ndef _build_resistance_timeline(reports: List[CultureReport]) -> List[List[str]]:\n    \"\"\"Return per-report resistance marker lists, in report order.\"\"\"\n    return [list(r.resistance_markers) for r in reports]\n\n\n# ---------------------------------------------------------------------------\n# Public API\n# ---------------------------------------------------------------------------\n\n\ndef analyze_trend(reports: List[CultureReport]) -> TrendResult:\n    \"\"\"\n    Compute a TrendResult from an ordered list of CultureReport objects.\n\n    Reports should be sorted by date (oldest first) before calling this\n    function. The function does NOT re-sort \u2014 caller is responsible.\n\n    Args:\n        reports: 1\u20133 CultureReport instances in chronological order.\n\n    Returns:\n        TrendResult with all temporal signal fields populated.\n    \"\"\"\n    if not reports:\n        raise ValueError(\"analyze_trend requires at least one CultureReport.\")\n\n    cfu_values = [r.cfu for r in reports]\n    cfu_deltas = _compute_deltas(cfu_values)\n    cfu_trend = _classify_cfu_trend(cfu_values)\n    organism_list = [r.organism for r in reports]\n    organism_persistent = _check_persistence(organism_list)\n    resistance_evolution = _check_resistance_evolution(reports)\n    resistance_timeline = _build_resistance_timeline(reports)\n    report_dates = [r.date for r in reports]\n    any_contamination = any(r.contamination_flag for r in reports)\n\n    return TrendResult(\n        cfu_trend=cfu_trend,\n        cfu_values=cfu_values,\n        cfu_deltas=cfu_deltas,\n        organism_persistent=organism_persistent,\n        organism_list=organism_list,\n        resistance_evolution=resistance_evolution,\n        resistance_timeline=resistance_timeline,\n        report_dates=report_dates,\n        any_contamination=any_contamination,\n    )"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# --- Trend Unit Tests ---\n\n\n_PASS = 0\n_FAIL = 0\n\n\ndef _assert(condition: bool, msg: str) -> None:\n    global _PASS, _FAIL\n    if condition:\n        _PASS += 1\n        print(f\"  PASS  {msg}\")\n    else:\n        _FAIL += 1\n        print(f\"  FAIL  {msg}\")\n\n\ndef _make_report(\n    cfu: int,\n    organism: str = \"Escherichia coli\",\n    date: str = \"2026-01-01\",\n    markers=None,\n    contamination: bool = False,\n) -> CultureReport:\n    return CultureReport(\n        date=date,\n        organism=organism,\n        cfu=cfu,\n        resistance_markers=markers or [],\n        specimen_type=\"urine\",\n        contamination_flag=contamination,\n        raw_text=\"<stub>\",\n    )\n\n\n# ---------------------------------------------------------------------------\n# 1. Monotonically decreasing\n# ---------------------------------------------------------------------------\nprint(\"=== Test: Monotonically Decreasing CFU ===\")\nrpts = [\n    _make_report(120000, date=\"2026-01-01\"),\n    _make_report(40000, date=\"2026-01-10\"),\n    _make_report(5000, date=\"2026-01-20\"),\n]\nt = analyze_trend(rpts)\n_assert(t.cfu_trend == \"decreasing\", f\"trend == 'decreasing'  (got '{t.cfu_trend}')\")\n_assert(t.cfu_deltas == [-80000, -35000], f\"deltas correct  (got {t.cfu_deltas})\")\n_assert(t.organism_persistent is True, f\"organism_persistent == True\")\n_assert(t.resistance_evolution is False, f\"resistance_evolution == False\")\n_assert(t.any_contamination is False, f\"any_contamination == False\")\n\n# ---------------------------------------------------------------------------\n# 2. Cleared (final CFU \u2264 1000) \u2014 overrides decreasing\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Cleared (Final CFU \u2264 1000) ===\")\nrpts2 = [\n    _make_report(120000, date=\"2026-01-01\"),\n    _make_report(40000, date=\"2026-01-10\"),\n    _make_report(800, date=\"2026-01-20\"),\n]\nt2 = analyze_trend(rpts2)\n_assert(t2.cfu_trend == \"cleared\", f\"trend == 'cleared'  (got '{t2.cfu_trend}')\")\n\n# ---------------------------------------------------------------------------\n# 3. CFU = 0 (no growth) \u2192 also cleared\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Zero CFU (No Growth) ===\")\nrpts3 = [\n    _make_report(80000, date=\"2026-01-01\"),\n    _make_report(0, date=\"2026-01-10\"),\n]\nt3 = analyze_trend(rpts3)\n_assert(\n    t3.cfu_trend == \"cleared\", f\"trend == 'cleared' for CFU=0  (got '{t3.cfu_trend}')\"\n)\n\n# ---------------------------------------------------------------------------\n# 4. Monotonically increasing\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Monotonically Increasing CFU ===\")\nrpts4 = [\n    _make_report(40000, date=\"2026-01-01\"),\n    _make_report(80000, date=\"2026-01-10\"),\n    _make_report(120000, date=\"2026-01-20\"),\n]\nt4 = analyze_trend(rpts4)\n_assert(t4.cfu_trend == \"increasing\", f\"trend == 'increasing'  (got '{t4.cfu_trend}')\")\n\n# ---------------------------------------------------------------------------\n# 5. Fluctuating\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Fluctuating CFU ===\")\nrpts5 = [\n    _make_report(80000, date=\"2026-01-01\"),\n    _make_report(120000, date=\"2026-01-10\"),\n    _make_report(60000, date=\"2026-01-20\"),\n]\nt5 = analyze_trend(rpts5)\n_assert(\n    t5.cfu_trend == \"fluctuating\", f\"trend == 'fluctuating'  (got '{t5.cfu_trend}')\"\n)\n\n# ---------------------------------------------------------------------------\n# 6. Single report \u2014 insufficient_data\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Single Report (Insufficient Data) ===\")\nrpts6 = [_make_report(100000, date=\"2026-01-01\")]\nt6 = analyze_trend(rpts6)\n_assert(\n    t6.cfu_trend == \"insufficient_data\",\n    f\"trend == 'insufficient_data'  (got '{t6.cfu_trend}')\",\n)\n_assert(t6.cfu_deltas == [], f\"deltas == []  (got {t6.cfu_deltas})\")\n\n# ---------------------------------------------------------------------------\n# 7. Resistance evolution detection\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Resistance Evolution ===\")\nrpts7 = [\n    _make_report(90000, date=\"2026-01-01\", markers=[]),\n    _make_report(80000, date=\"2026-01-10\", markers=[]),\n    _make_report(75000, date=\"2026-01-20\", markers=[\"ESBL\"]),\n]\nt7 = analyze_trend(rpts7)\n_assert(t7.resistance_evolution is True, f\"resistance_evolution == True\")\n_assert(t7.resistance_timeline[2] == [\"ESBL\"], f\"resistance_timeline[2] == ['ESBL']\")\n\n# ---------------------------------------------------------------------------\n# 8. Organism change (not persistent)\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Organism Change ===\")\nrpts8 = [\n    _make_report(100000, organism=\"Escherichia coli\", date=\"2026-01-01\"),\n    _make_report(90000, organism=\"Klebsiella pneumoniae\", date=\"2026-01-10\"),\n]\nt8 = analyze_trend(rpts8)\n_assert(\n    t8.organism_persistent is False,\n    f\"organism_persistent == False when organism changes\",\n)\n\n# ---------------------------------------------------------------------------\n# 9. Contamination flag propagation\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Contamination Propagation ===\")\nrpts9 = [\n    _make_report(5000, organism=\"mixed flora\", date=\"2026-01-01\", contamination=True),\n    _make_report(3000, organism=\"mixed flora\", date=\"2026-01-10\", contamination=True),\n]\nt9 = analyze_trend(rpts9)\n_assert(t9.any_contamination is True, f\"any_contamination == True\")\n\n# ---------------------------------------------------------------------------\n# Summary\n# ---------------------------------------------------------------------------\nprint(f\"\\n{'=' * 50}\")\nprint(f\"Trend Tests Complete: {_PASS} passed, {_FAIL} failed\")\nif _FAIL == 0:\n    print(\"ALL TESTS PASSED\")\nelse:\n    print(f\"WARNING: {_FAIL} test(s) failed\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell E: Hypothesis Update Layer"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom typing import List\n\n\n\n# ---------------------------------------------------------------------------\n# Risk flag constants\n# ---------------------------------------------------------------------------\nFLAG_EMERGING_RESISTANCE = \"EMERGING_RESISTANCE\"\nFLAG_CONTAMINATION = \"CONTAMINATION_SUSPECTED\"\nFLAG_NON_RESPONSE = \"NON_RESPONSE_PATTERN\"\nFLAG_INSUFFICIENT_DATA = \"INSUFFICIENT_DATA\"\nFLAG_ORGANISM_CHANGE = \"ORGANISM_CHANGE\"\n\n\n# ---------------------------------------------------------------------------\n# Confidence scoring\n# ---------------------------------------------------------------------------\n\n\ndef _score_confidence(trend: TrendResult, report_count: int) -> float:\n    \"\"\"\n    Apply deterministic signal adjustments to a base confidence value.\n\n    Starting point: RULES[\"base_confidence\"] = 0.50\n    Each signal adds or subtracts a fixed delta.\n    Final value is clamped to [0.0, RULES[\"max_confidence\"]].\n\n    Signal table (Section 7.1):\n        +0.30  CFU decreasing\n        +0.40  CFU cleared\n        +0.20  CFU increasing  (high confidence of non-response)\n        -0.10  CFU fluctuating\n        -0.10  resistance evolution\n        -0.05  organism changed\n        -0.20  contamination present\n        -0.25  fewer than 2 reports\n    \"\"\"\n    confidence = RULES[\"base_confidence\"]\n\n    # Trend signal\n    if trend.cfu_trend == \"decreasing\":\n        confidence += 0.30\n    elif trend.cfu_trend == \"cleared\":\n        confidence += 0.40\n    elif trend.cfu_trend == \"increasing\":\n        confidence += 0.20  # high confidence of non-response\n    elif trend.cfu_trend == \"fluctuating\":\n        confidence -= 0.10\n\n    # Resistance evolution penalty\n    if trend.resistance_evolution:\n        confidence -= 0.10\n\n    # Organism change uncertainty\n    if not trend.organism_persistent:\n        confidence -= 0.05\n\n    # Contamination validity concern\n    if trend.any_contamination:\n        confidence -= 0.20\n\n    # Insufficient data penalty\n    if report_count < 2:\n        confidence -= 0.25\n\n    # Hard clamp: never < 0.0, never > max_confidence (epistemic humility)\n    return round(max(0.0, min(confidence, RULES[\"max_confidence\"])), 4)\n\n\n# ---------------------------------------------------------------------------\n# Risk flag assignment (Section 7.2)\n# ---------------------------------------------------------------------------\n\n\ndef _assign_risk_flags(trend: TrendResult, report_count: int) -> List[str]:\n    \"\"\"Build a list of risk flag strings from trend signals.\"\"\"\n    flags: List[str] = []\n\n    if trend.resistance_evolution:\n        flags.append(FLAG_EMERGING_RESISTANCE)\n\n    if trend.any_contamination:\n        flags.append(FLAG_CONTAMINATION)\n\n    if trend.cfu_trend == \"increasing\":\n        flags.append(FLAG_NON_RESPONSE)\n\n    if report_count < 2:\n        flags.append(FLAG_INSUFFICIENT_DATA)\n\n    if not trend.organism_persistent:\n        flags.append(FLAG_ORGANISM_CHANGE)\n\n    return flags\n\n\n# ---------------------------------------------------------------------------\n# Interpretation string construction (Section 7.3)\n# ---------------------------------------------------------------------------\n\n\ndef _build_interpretation(trend: TrendResult, report_count: int) -> str:\n    \"\"\"\n    Construct a rule-generated natural language pattern summary.\n\n    This string is passed to MedGemma only as structured context inside\n    the JSON payload \u2014 never as a direct LLM prompt.\n    \"\"\"\n    parts: List[str] = []\n\n    if trend.cfu_trend == \"decreasing\":\n        parts.append(\"Pattern suggests improving infection response.\")\n    elif trend.cfu_trend == \"cleared\":\n        parts.append(\"Pattern suggests possible resolution.\")\n    elif trend.cfu_trend == \"increasing\":\n        parts.append(\"Pattern suggests possible non-response.\")\n    elif trend.cfu_trend == \"fluctuating\":\n        parts.append(\"Pattern is variable \u2014 requires clinical context.\")\n    elif trend.cfu_trend == \"insufficient_data\":\n        parts.append(\"Insufficient longitudinal data for trend analysis.\")\n\n    if trend.resistance_evolution:\n        parts.append(\"Emerging resistance observed.\")\n\n    if not trend.organism_persistent:\n        parts.append(\"Organism change may indicate reinfection.\")\n\n    if trend.any_contamination:\n        parts.append(\"Contamination suspected \u2014 interpret with caution.\")\n\n    return \" \".join(parts)\n\n\n# ---------------------------------------------------------------------------\n# Public API\n# ---------------------------------------------------------------------------\n\n\ndef generate_hypothesis(trend: TrendResult, report_count: int) -> HypothesisResult:\n    \"\"\"\n    Generate a deterministic hypothesis from a TrendResult.\n\n    Args:\n        trend: Computed TrendResult from the trend engine.\n        report_count: Number of source reports (used for insufficient-data logic).\n\n    Returns:\n        HypothesisResult with confidence score, risk flags, interpretation,\n        stewardship alert, and mandatory clinician review flag.\n    \"\"\"\n    confidence = _score_confidence(trend, report_count)\n    risk_flags = _assign_risk_flags(trend, report_count)\n    interpretation = _build_interpretation(trend, report_count)\n    stewardship_alert = trend.resistance_evolution\n\n    return HypothesisResult(\n        interpretation=interpretation,\n        confidence=confidence,\n        risk_flags=risk_flags,\n        stewardship_alert=stewardship_alert,\n        requires_clinician_review=True,  # Always True \u2014 structural safety guarantee\n    )"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# --- Hypothesis Unit Tests ---\n\n\n_PASS = 0\n_FAIL = 0\n\n\ndef _assert(condition: bool, msg: str) -> None:\n    global _PASS, _FAIL\n    if condition:\n        _PASS += 1\n        print(f\"  PASS  {msg}\")\n    else:\n        _FAIL += 1\n        print(f\"  FAIL  {msg}\")\n\n\ndef _make_report(\n    cfu: int,\n    organism: str = \"Escherichia coli\",\n    date: str = \"2026-01-01\",\n    markers=None,\n    contamination: bool = False,\n) -> CultureReport:\n    return CultureReport(\n        date=date,\n        organism=organism,\n        cfu=cfu,\n        resistance_markers=markers or [],\n        specimen_type=\"urine\",\n        contamination_flag=contamination,\n        raw_text=\"<stub>\",\n    )\n\n\n# ---------------------------------------------------------------------------\n# 1. Perfect improvement (decreasing \u2192 cleared) \u2014 confidence \u2265 0.80\n# ---------------------------------------------------------------------------\nprint(\"=== Test: Perfect Improvement (Decreasing \u2192 Cleared) ===\")\nrpts = [\n    _make_report(120000, date=\"2026-01-01\"),\n    _make_report(40000, date=\"2026-01-10\"),\n    _make_report(800, date=\"2026-01-20\"),  # cleared (\u2264 1000)\n]\ntrend = analyze_trend(rpts)\nhyp = generate_hypothesis(trend, len(rpts))\n\n_assert(\n    hyp.confidence >= 0.80,\n    f\"confidence \u2265 0.80 for cleared trend  (got {hyp.confidence})\",\n)\n_assert(\n    hyp.confidence <= 0.95, f\"confidence \u2264 0.95 (hard ceiling)  (got {hyp.confidence})\"\n)\n_assert(hyp.stewardship_alert is False, f\"stewardship_alert == False\")\n_assert(hyp.requires_clinician_review is True, f\"requires_clinician_review always True\")\n_assert(\n    \"possible resolution\" in hyp.interpretation, f\"interpretation mentions resolution\"\n)\n\n# ---------------------------------------------------------------------------\n# 2. Emerging resistance \u2014 confidence drops vs. clean improving scenario\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Emerging Resistance (Confidence Drops) ===\")\nrpts2 = [\n    _make_report(90000, date=\"2026-01-01\", markers=[]),\n    _make_report(80000, date=\"2026-01-10\", markers=[]),\n    _make_report(75000, date=\"2026-01-20\", markers=[\"ESBL\"]),\n]\ntrend2 = analyze_trend(rpts2)\nhyp2 = generate_hypothesis(trend2, len(rpts2))\n\n_assert(\n    FLAG_EMERGING_RESISTANCE in hyp2.risk_flags, f\"EMERGING_RESISTANCE in risk_flags\"\n)\n_assert(hyp2.stewardship_alert is True, f\"stewardship_alert == True\")\n_assert(\n    hyp2.confidence < 0.80,\n    f\"confidence < 0.80 when resistance emerges  (got {hyp2.confidence})\",\n)\n\n# ---------------------------------------------------------------------------\n# 3. Contamination \u2014 confidence is reduced by the -0.20 contamination penalty.\n#    With decreasing CFU (5000\u21923000): base 0.50 + 0.30 (decreasing) - 0.20 (contamination) = 0.60\n#    The PRD Appendix B example uses a fluctuating pattern; here decreasing gives 0.60.\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Contamination (Confidence Drops Sharply) ===\")\nrpts3 = [\n    _make_report(5000, organism=\"mixed flora\", date=\"2026-01-01\", contamination=True),\n    _make_report(3000, organism=\"mixed flora\", date=\"2026-01-10\", contamination=True),\n]\ntrend3 = analyze_trend(rpts3)\nhyp3 = generate_hypothesis(trend3, len(rpts3))\n\n_assert(FLAG_CONTAMINATION in hyp3.risk_flags, f\"CONTAMINATION_SUSPECTED in risk_flags\")\n_assert(\n    hyp3.confidence <= 0.65,\n    f\"confidence reduced by contamination penalty (got {hyp3.confidence})\",\n)\n_assert(\n    \"Contamination suspected\" in hyp3.interpretation,\n    f\"interpretation flags contamination\",\n)\n\n# ---------------------------------------------------------------------------\n# 4. Single report \u2014 insufficient data penalty\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Single Report (Insufficient Data) ===\")\nrpts4 = [_make_report(100000, date=\"2026-01-01\")]\ntrend4 = analyze_trend(rpts4)\nhyp4 = generate_hypothesis(trend4, len(rpts4))\n\n_assert(\n    hyp4.confidence == 0.25,\n    f\"confidence == 0.25 (base 0.50 - 0.25)  (got {hyp4.confidence})\",\n)\n_assert(\"INSUFFICIENT_DATA\" in hyp4.risk_flags, f\"INSUFFICIENT_DATA in risk_flags\")\n\n# ---------------------------------------------------------------------------\n# 5. Increasing CFU \u2014 non-response pattern\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Increasing CFU (Non-Response) ===\")\nrpts5 = [\n    _make_report(40000, date=\"2026-01-01\"),\n    _make_report(80000, date=\"2026-01-10\"),\n    _make_report(120000, date=\"2026-01-20\"),\n]\ntrend5 = analyze_trend(rpts5)\nhyp5 = generate_hypothesis(trend5, len(rpts5))\n\n_assert(\n    \"NON_RESPONSE_PATTERN\" in hyp5.risk_flags, f\"NON_RESPONSE_PATTERN in risk_flags\"\n)\n_assert(\n    hyp5.confidence == 0.70,\n    f\"confidence == 0.70 (0.50 + 0.20)  (got {hyp5.confidence})\",\n)\n_assert(\n    \"non-response\" in hyp5.interpretation.lower(),\n    f\"interpretation mentions non-response\",\n)\n\n# ---------------------------------------------------------------------------\n# 6. Confidence never exceeds 0.95\n# ---------------------------------------------------------------------------\nprint(\"\\n=== Test: Confidence Hard Ceiling ===\")\n# Best possible scenario: cleared, persistent, no resistance, no contamination\nrpts6 = [\n    _make_report(120000, date=\"2026-01-01\"),\n    _make_report(800, date=\"2026-01-10\"),  # cleared\n]\ntrend6 = analyze_trend(rpts6)\nhyp6 = generate_hypothesis(trend6, len(rpts6))\n_assert(\n    hyp6.confidence <= 0.95, f\"confidence never exceeds 0.95  (got {hyp6.confidence})\"\n)\n\n# ---------------------------------------------------------------------------\n# Summary\n# ---------------------------------------------------------------------------\nprint(f\"\\n{'=' * 50}\")\nprint(f\"Hypothesis Tests Complete: {_PASS} passed, {_FAIL} failed\")\nif _FAIL == 0:\n    print(\"ALL TESTS PASSED\")\nelse:\n    print(f\"WARNING: {_FAIL} test(s) failed\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell F: MedGemma Integration"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom __future__ import annotations\n\nimport json\nimport warnings\nfrom dataclasses import asdict\nfrom typing import Optional\n\n\n# ---------------------------------------------------------------------------\n# Model ID\n# ---------------------------------------------------------------------------\nMODEL_ID = \"google/medgemma-4b-it\"  # Instruction-tuned variant\n\n# ---------------------------------------------------------------------------\n# System prompts (Section 8.3 / 8.4)\n# ---------------------------------------------------------------------------\n\nPATIENT_SYSTEM_PROMPT = \"\"\"\nYou are a compassionate medical communication assistant.\nYou are given STRUCTURED DATA only --- not raw patient reports.\nYour task: Generate a plain-language explanation of a lab result trend.\n\nSTRICT RULES:\n1. NEVER diagnose. Never say \"you have X\".\n2. NEVER recommend a treatment or medication.\n3. Always end with: \"Please discuss these findings with your doctor.\"\n4. Use empathetic, reassuring language.\n5. Respond ONLY based on the structured data provided.\n6. Do not reference specific bacteria names to the patient.\n\"\"\".strip()\n\nCLINICIAN_SYSTEM_PROMPT = \"\"\"\nYou are a structured clinical decision support assistant.\nYou are given STRUCTURED TEMPORAL DATA from a rule-based analysis engine.\nYour task: Generate a structured trajectory interpretation for a clinician.\n\nSTRICT RULES:\n1. Frame all outputs as hypotheses, not diagnoses.\n2. Always include confidence score in output.\n3. Flag stewardship concerns explicitly if resistance_evolution is True.\n4. End with: \"Clinical interpretation requires full patient context.\"\n5. Use clinical terminology appropriate for a physician audience.\n6. Never recommend a specific antibiotic or treatment regimen.\n\"\"\".strip()\n\n# ---------------------------------------------------------------------------\n# Payload builder (Section 8.5)\n# raw_text is NEVER included \u2014 only derived structured fields\n# ---------------------------------------------------------------------------\n\n\ndef build_medgemma_payload(\n    trend: TrendResult,\n    hypothesis: HypothesisResult,\n    mode: str,\n) -> str:\n    \"\"\"\n    Build a JSON string to pass as the user turn to MedGemma.\n\n    IMPORTANT: raw_text from CultureReport is explicitly excluded.\n    Only deterministic derived fields are forwarded.\n\n    Args:\n        trend:      Computed TrendResult.\n        hypothesis: Computed HypothesisResult.\n        mode:       \"patient\" | \"clinician\"\n\n    Returns:\n        JSON string ready to embed in a chat message.\n    \"\"\"\n    if mode not in (\"patient\", \"clinician\"):\n        raise ValueError(f\"mode must be 'patient' or 'clinician', got '{mode}'\")\n\n    payload = {\n        \"mode\": mode,\n        \"cfu_trend\": trend.cfu_trend,\n        \"cfu_values\": trend.cfu_values,\n        \"cfu_deltas\": trend.cfu_deltas,\n        \"organism_persistent\": trend.organism_persistent,\n        \"resistance_evolution\": trend.resistance_evolution,\n        \"resistance_timeline\": trend.resistance_timeline,\n        \"any_contamination\": trend.any_contamination,\n        \"report_dates\": trend.report_dates,\n        \"interpretation\": hypothesis.interpretation,\n        \"confidence\": hypothesis.confidence,\n        \"risk_flags\": hypothesis.risk_flags,\n        \"stewardship_alert\": hypothesis.stewardship_alert,\n        \"requires_clinician_review\": hypothesis.requires_clinician_review,\n        # raw_text intentionally omitted \u2014 safety guarantee\n    }\n    return json.dumps(payload, indent=2)\n\n\n# ---------------------------------------------------------------------------\n# Model loading \u2014 with CPU fallback stub\n# ---------------------------------------------------------------------------\n\n\ndef load_medgemma(\n    model_id: str = MODEL_ID,\n) -> tuple:\n    \"\"\"\n    Attempt to load MedGemma from HuggingFace.\n\n    Returns:\n        (model, tokenizer, is_stub) tuple.\n        is_stub=True means the stub fallback is active (no GPU / model unavailable).\n\n    GPU note (Kaggle): accelerator=GPU T4 x2, bfloat16 reduces VRAM to ~4 GB.\n    \"\"\"\n    try:\n        import torch\n        from transformers import AutoTokenizer, AutoModelForCausalLM\n\n        gpu_available = torch.cuda.is_available()\n        if not gpu_available:\n            warnings.warn(\n                \"No CUDA GPU detected. Activating MedGemma stub fallback. \"\n                \"Outputs will be templated, not LLM-generated.\",\n                UserWarning,\n                stacklevel=2,\n            )\n            return None, None, True\n\n        print(f\"Loading {model_id} on GPU ({torch.cuda.get_device_name(0)}) ...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_id)\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\",\n        )\n        model.eval()\n        print(\"MedGemma loaded successfully.\")\n        return model, tokenizer, False\n\n    except Exception as exc:\n        warnings.warn(\n            f\"MedGemma model loading failed ({exc}). Activating stub fallback.\",\n            UserWarning,\n            stacklevel=2,\n        )\n        return None, None, True\n\n\n# ---------------------------------------------------------------------------\n# Stub fallback response templates\n# ---------------------------------------------------------------------------\n\n\ndef _stub_response(mode: str, trend: TrendResult, hypothesis: HypothesisResult) -> str:\n    \"\"\"\n    Return a hardcoded template response when MedGemma is unavailable.\n    Used for CPU-only Kaggle kernels or when model loading fails.\n    \"\"\"\n    if mode == \"patient\":\n        trend_desc = {\n            \"decreasing\": \"a downward trend in your lab values\",\n            \"cleared\": \"that your lab values have returned to a normal range\",\n            \"increasing\": \"an upward trend in your lab values\",\n            \"fluctuating\": \"a variable pattern in your lab values\",\n            \"insufficient_data\": \"limited data \u2014 only one result is available\",\n        }.get(trend.cfu_trend, \"an uncertain pattern in your lab values\")\n\n        flags_note = \"\"\n        if trend.resistance_evolution:\n            flags_note = (\n                \" Your doctor may want to discuss the latest results in detail.\"\n            )\n\n        return (\n            f\"Your lab results show {trend_desc} over the time period reviewed. \"\n            f\"This information has been summarised for your awareness.{flags_note} \"\n            \"Please discuss these findings with your doctor.\"\n        )\n\n    else:  # clinician\n        flags = \", \".join(hypothesis.risk_flags) if hypothesis.risk_flags else \"None\"\n        stewardship = (\n            \"ALERT: Antimicrobial stewardship review recommended.\"\n            if hypothesis.stewardship_alert\n            else \"\"\n        )\n        return (\n            f\"Trajectory Hypothesis Summary\\n\"\n            f\"CFU Trend: {trend.cfu_trend}\\n\"\n            f\"Organism Persistent: {trend.organism_persistent}\\n\"\n            f\"Resistance Evolution: {trend.resistance_evolution}\\n\"\n            f\"Confidence: {hypothesis.confidence:.2f} ({hypothesis.confidence * 100:.0f}%)\\n\"\n            f\"Risk Flags: {flags}\\n\"\n            f\"{stewardship}\\n\"\n            f\"Interpretation: {hypothesis.interpretation}\\n\"\n            \"Clinical interpretation requires full patient context.\"\n        ).strip()\n\n\n# ---------------------------------------------------------------------------\n# Main inference function (Section F-4)\n# ---------------------------------------------------------------------------\n\n\ndef call_medgemma(\n    trend: TrendResult,\n    hypothesis: HypothesisResult,\n    mode: str,\n    model=None,\n    tokenizer=None,\n    is_stub: bool = True,\n) -> str:\n    \"\"\"\n    Call MedGemma with a fully structured JSON payload.\n\n    If is_stub=True (no GPU / model unavailable), returns a templated\n    fallback response so the notebook continues to execute end-to-end.\n\n    Generation parameters (Section 8.6):\n        max_new_tokens=512, temperature=0.3, top_p=0.9,\n        do_sample=True, repetition_penalty=1.1\n\n    Args:\n        trend:      TrendResult from trend engine.\n        hypothesis: HypothesisResult from hypothesis layer.\n        mode:       \"patient\" | \"clinician\"\n        model:      Loaded HuggingFace model (None if stub).\n        tokenizer:  Loaded HuggingFace tokenizer (None if stub).\n        is_stub:    True \u2192 use stub fallback.\n\n    Returns:\n        Decoded string response (special tokens stripped).\n    \"\"\"\n    if is_stub or model is None or tokenizer is None:\n        return _stub_response(mode, trend, hypothesis)\n\n    import torch\n\n    system_prompt = (\n        PATIENT_SYSTEM_PROMPT if mode == \"patient\" else CLINICIAN_SYSTEM_PROMPT\n    )\n    user_content = build_medgemma_payload(trend, hypothesis, mode)\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_content},\n    ]\n\n    # Apply chat template\n    input_ids = tokenizer.apply_chat_template(\n        messages,\n        return_tensors=\"pt\",\n        add_generation_prompt=True,\n    ).to(model.device)\n\n    with torch.no_grad():\n        output_ids = model.generate(\n            input_ids,\n            max_new_tokens=512,\n            temperature=0.3,\n            top_p=0.9,\n            do_sample=True,\n            repetition_penalty=1.1,\n        )\n\n    # Decode only the newly generated tokens\n    new_tokens = output_ids[0][input_ids.shape[-1] :]\n    response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n    return response.strip()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell G: Output Renderer"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom __future__ import annotations\n\nfrom typing import Optional\n\n\n# ---------------------------------------------------------------------------\n# G-1: Renderer Constants (Section 9.2\u20139.4, 9.6)\n# ---------------------------------------------------------------------------\n\nTREND_PHRASES: dict[str, str] = {\n    \"decreasing\": \"a downward trend in bacterial count\",\n    \"cleared\": \"resolution of detectable bacteria\",\n    \"increasing\": \"an upward trend in bacterial count\",\n    \"fluctuating\": \"a variable pattern in bacterial count\",\n    \"insufficient_data\": \"only one data point available\",\n}\n\nPATIENT_QUESTIONS: list[str] = [\n    \"Is this trend consistent with my symptoms improving?\",\n    \"Do I need another follow-up culture test?\",\n    \"Are there any signs of antibiotic resistance I should know about?\",\n]\n\nPATIENT_DISCLAIMER: str = (\n    \"IMPORTANT: This is an educational interpretation only. \"\n    \"It is NOT a medical diagnosis. \"\n    \"Please discuss all lab results with your healthcare provider.\"\n)\n\nCLINICIAN_DISCLAIMER: str = (\n    \"This output represents a structured hypothesis for clinical review. \"\n    \"It is NOT a diagnosis and does NOT replace clinical judgment. \"\n    \"All interpretations require full patient context and physician evaluation.\"\n)\n\n\n# ---------------------------------------------------------------------------\n# G-2: render_patient_output()\n# ---------------------------------------------------------------------------\n\n\ndef render_patient_output(\n    trend: TrendResult,\n    hypothesis: HypothesisResult,\n    medgemma_response: str,\n) -> FormattedOutput:\n    \"\"\"\n    Construct a FormattedOutput for Patient Mode.\n\n    Args:\n        trend:             TrendResult from trend engine.\n        hypothesis:        HypothesisResult from hypothesis layer.\n        medgemma_response: String from call_medgemma() in 'patient' mode.\n\n    Returns:\n        FormattedOutput with patient_* fields populated.\n        patient_disclaimer is ALWAYS appended unconditionally.\n    \"\"\"\n    trend_phrase = TREND_PHRASES.get(trend.cfu_trend, \"an uncertain pattern\")\n    confidence_note = f\"Interpretation confidence: {hypothesis.confidence:.2f}\"\n\n    # Cap MedGemma explanation to ~150 words (soft limit)\n    explanation_words = medgemma_response.split()\n    if len(explanation_words) > 150:\n        explanation = \" \".join(explanation_words[:150]) + \"...\"\n    else:\n        explanation = medgemma_response\n\n    return FormattedOutput(\n        mode=\"patient\",\n        patient_trend_phrase=trend_phrase,\n        patient_explanation=f\"{explanation}\\n\\n{confidence_note}\",\n        patient_questions=list(PATIENT_QUESTIONS),\n        patient_disclaimer=PATIENT_DISCLAIMER,\n    )\n\n\n# ---------------------------------------------------------------------------\n# G-3: render_clinician_output()\n# ---------------------------------------------------------------------------\n\n\ndef render_clinician_output(\n    trend: TrendResult,\n    hypothesis: HypothesisResult,\n    medgemma_response: str,\n) -> FormattedOutput:\n    \"\"\"\n    Construct a FormattedOutput for Clinician Mode.\n\n    Args:\n        trend:             TrendResult from trend engine.\n        hypothesis:        HypothesisResult from hypothesis layer.\n        medgemma_response: String from call_medgemma() in 'clinician' mode.\n\n    Returns:\n        FormattedOutput with clinician_* fields populated.\n        resistance_detail is only populated when resistance markers are present.\n        clinician_disclaimer is ALWAYS appended unconditionally.\n    \"\"\"\n    trajectory_summary: dict = {\n        \"report_dates\": trend.report_dates,\n        \"cfu_values\": trend.cfu_values,\n        \"cfu_deltas\": trend.cfu_deltas,\n        \"cfu_trend\": trend.cfu_trend,\n        \"organism_list\": trend.organism_list,\n        \"organism_persistent\": trend.organism_persistent,\n        \"any_contamination\": trend.any_contamination,\n        \"resistance_evolution\": trend.resistance_evolution,\n    }\n\n    # Build resistance detail only when resistance markers are present\n    resistance_detail: Optional[str] = None\n    has_any_resistance = any(markers for markers in trend.resistance_timeline)\n    if has_any_resistance:\n        lines = []\n        for date, markers in zip(trend.report_dates, trend.resistance_timeline):\n            marker_str = \", \".join(markers) if markers else \"None\"\n            lines.append(f\"  {date}: {marker_str}\")\n        resistance_detail = \"Resistance Timeline:\\n\" + \"\\n\".join(lines)\n\n    return FormattedOutput(\n        mode=\"clinician\",\n        clinician_trajectory=trajectory_summary,\n        clinician_interpretation=medgemma_response,\n        clinician_confidence=hypothesis.confidence,\n        clinician_resistance_detail=resistance_detail,\n        clinician_stewardship_flag=hypothesis.stewardship_alert,\n        clinician_disclaimer=CLINICIAN_DISCLAIMER,\n    )\n\n\n# ---------------------------------------------------------------------------\n# G-4: display_output()  \u2014 HTML-formatted Kaggle notebook rendering\n# ---------------------------------------------------------------------------\n\n\ndef display_output(\n    patient_out: FormattedOutput,\n    clinician_out: FormattedOutput,\n    scenario_name: str = \"Culture Analysis\",\n) -> None:\n    \"\"\"\n    Pretty-print both FormattedOutput objects using IPython HTML display.\n\n    Falls back to plain-text print() when IPython is unavailable\n    (e.g., running tests from the CLI).\n    \"\"\"\n    html = _build_html(patient_out, clinician_out, scenario_name)\n\n    try:\n        from IPython.display import display, HTML\n\n        display(HTML(html))\n    except ImportError:\n        # CLI / non-notebook fallback\n        _print_plain(patient_out, clinician_out, scenario_name)\n\n\ndef _build_html(\n    patient_out: FormattedOutput,\n    clinician_out: FormattedOutput,\n    scenario_name: str,\n) -> str:\n    \"\"\"Build the HTML string for Kaggle notebook cell output.\"\"\"\n\n    # ---- Patient section ----\n    questions_html = \"\".join(\n        f\"<li>{q}</li>\" for q in (patient_out.patient_questions or [])\n    )\n\n    # ---- Resistance / stewardship ----\n    resistance_html = \"\"\n    if clinician_out.clinician_resistance_detail:\n        resistance_html = f\"\"\"\n        <div style=\"background:#FDFAF7;border-left:3px solid #E8DDD6;padding:10px 14px;margin:10px 0;border-radius:3px;\">\n          <p style=\"margin:0 0 4px 0;font-family:system-ui,sans-serif;font-size:0.8rem;font-weight:600;letter-spacing:.04em;text-transform:uppercase;color:#7a6558;\">Resistance Timeline</p>\n          <pre style=\"margin:0;font-size:12px;font-family:system-ui,monospace;color:#4a3728;white-space:pre-wrap;\">{clinician_out.clinician_resistance_detail}</pre>\n        </div>\n        \"\"\"\n\n    stewardship_html = \"\"\n    if clinician_out.clinician_stewardship_flag:\n        stewardship_html = \"\"\"\n        <div style=\"background:#fdf5f1;border-left:3px solid #C1622F;padding:10px 14px;margin:10px 0;border-radius:3px;\">\n          <span style=\"font-family:system-ui,sans-serif;font-size:0.85rem;color:#C1622F;font-weight:600;\">\u26a0 Stewardship Alert</span>\n          <p style=\"margin:4px 0 0 0;font-family:system-ui,sans-serif;font-size:0.82rem;color:#6b3320;\">Emerging resistance detected \u2014 antimicrobial stewardship review recommended.</p>\n        </div>\n        \"\"\"\n\n    # ---- Trajectory table ----\n    traj = clinician_out.clinician_trajectory or {}\n    traj_rows = \"\".join(\n        f\"<tr>\"\n        f\"<td style='padding:5px 10px;border-bottom:1px solid #E8DDD6;border-right:1px solid #E8DDD6;\"\n        f\"font-family:system-ui,sans-serif;font-size:0.78rem;font-weight:600;color:#7a6558;\"\n        f\"text-transform:uppercase;letter-spacing:.03em;white-space:nowrap;'>{k}</td>\"\n        f\"<td style='padding:5px 10px;border-bottom:1px solid #E8DDD6;\"\n        f\"font-family:system-ui,sans-serif;font-size:0.82rem;color:#3d2b1f;'>{v}</td>\"\n        f\"</tr>\"\n        for k, v in traj.items()\n    )\n\n    # ---- Confidence bar ----\n    conf_val = clinician_out.clinician_confidence\n    conf_pct_num = int((conf_val or 0) * 100)\n    conf_label = (\n        f\"{conf_val:.0%}\" if conf_val is not None else \"N/A\"\n    )\n    conf_bar_html = f\"\"\"\n    <div style=\"margin:12px 0 16px;\">\n      <div style=\"display:flex;align-items:baseline;gap:8px;margin-bottom:5px;\">\n        <span style=\"font-family:system-ui,sans-serif;font-size:0.78rem;font-weight:600;color:#7a6558;text-transform:uppercase;letter-spacing:.04em;\">Confidence</span>\n        <span style=\"font-family:'Playfair Display',serif;font-size:1.15rem;font-weight:700;color:#C1622F;\">{conf_label}</span>\n      </div>\n      <div style=\"height:5px;border-radius:3px;background:#E8DDD6;overflow:hidden;\">\n        <div style=\"height:100%;width:{conf_pct_num}%;background:#C1622F;border-radius:3px;\"></div>\n      </div>\n    </div>\n    \"\"\"\n\n    # ---- Google Fonts import ----\n    font_import = (\n        '<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">'\n        '<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>'\n        '<link href=\"https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;600;700&'\n        'family=Lora:ital,wght@0,400;0,500;1,400&display=swap\" rel=\"stylesheet\">'\n    )\n\n    html = f\"\"\"\n    {font_import}\n    <div style=\"font-family:'Lora',serif;max-width:860px;margin:auto;color:#3d2b1f;background:#FDFAF7;padding:28px 32px;border:1px solid #E8DDD6;border-radius:4px;\">\n\n      <!-- Page header -->\n      <div style=\"text-align:center;border-bottom:1px solid #E8DDD6;padding-bottom:16px;margin-bottom:24px;\">\n        <h2 style=\"font-family:'Playfair Display',serif;font-weight:700;font-size:1.55rem;color:#C1622F;margin:0 0 4px 0;letter-spacing:.01em;\">\n          CultureSense\n        </h2>\n        <p style=\"font-family:system-ui,sans-serif;font-size:0.8rem;color:#9a8578;margin:0;letter-spacing:.06em;text-transform:uppercase;\">{scenario_name}</p>\n      </div>\n\n      <!-- PATIENT MODE -->\n      <section style=\"margin-bottom:28px;padding-bottom:24px;border-bottom:1px solid #E8DDD6;\">\n        <h3 style=\"font-family:'Playfair Display',serif;font-size:1.1rem;font-weight:600;color:#C1622F;margin:0 0 14px 0;letter-spacing:.01em;border-left:3px solid #C1622F;padding-left:10px;\">Patient Summary</h3>\n        <p style=\"font-size:1.0rem;line-height:1.7;margin:0 0 12px 0;\"><em>Your results show <strong>{patient_out.patient_trend_phrase}</strong>.</em></p>\n        <div style=\"line-height:1.75;color:#4a3728;font-size:0.97rem;\">\n          {(patient_out.patient_explanation or \"\").replace(chr(10), \"<br>\")}\n        </div>\n        <p style=\"margin:16px 0 6px 0;font-family:system-ui,sans-serif;font-size:0.78rem;font-weight:600;color:#7a6558;text-transform:uppercase;letter-spacing:.05em;\">Questions to ask your doctor</p>\n        <ul style=\"padding-left:18px;color:#4a3728;font-size:0.94rem;line-height:1.8;margin:0;\">\n          {questions_html.replace('<li>', '<li style=\"margin-bottom:4px;\">')}\n        </ul>\n        <div style=\"margin-top:18px;padding:10px 14px;border:1px solid #E8DDD6;border-radius:3px;background:#FDFAF7;\">\n          <p style=\"font-family:system-ui,sans-serif;font-size:0.78rem;font-style:italic;color:#9a8578;margin:0;line-height:1.6;\">{patient_out.patient_disclaimer}</p>\n        </div>\n      </section>\n\n      <!-- CLINICIAN MODE -->\n      <section>\n        <h3 style=\"font-family:'Playfair Display',serif;font-size:1.1rem;font-weight:600;color:#C1622F;margin:0 0 14px 0;letter-spacing:.01em;border-left:3px solid #C1622F;padding-left:10px;\">Clinical Interpretation</h3>\n        {conf_bar_html}\n        {stewardship_html}\n        {resistance_html}\n        <details style=\"margin:12px 0;border:1px solid #E8DDD6;border-radius:3px;\">\n          <summary style=\"cursor:pointer;padding:8px 12px;font-family:system-ui,sans-serif;font-size:0.8rem;font-weight:600;color:#7a6558;text-transform:uppercase;letter-spacing:.04em;list-style:none;user-select:none;\">\u25b8 Trajectory Data</summary>\n          <div style=\"padding:0 12px 12px;\">\n            <table style=\"border-collapse:collapse;width:100%;margin-top:8px;border:1px solid #E8DDD6;\">\n              {traj_rows}\n            </table>\n          </div>\n        </details>\n        <div style=\"line-height:1.75;color:#3d2b1f;font-size:0.97rem;margin-top:14px;\">\n          {(clinician_out.clinician_interpretation or \"\").replace(chr(10), \"<br>\")}\n        </div>\n        <p style=\"font-family:system-ui,sans-serif;font-style:italic;color:#9a8578;border-top:1px solid #E8DDD6;padding-top:12px;margin-top:20px;font-size:0.77rem;line-height:1.6;\">\n          {clinician_out.clinician_disclaimer}\n        </p>\n      </section>\n\n    </div>\n    \"\"\"\n    return html\n\n\ndef _print_plain(\n    patient_out: FormattedOutput,\n    clinician_out: FormattedOutput,\n    scenario_name: str,\n) -> None:\n    \"\"\"Plain-text fallback printer for non-notebook environments.\"\"\"\n    sep = \"=\" * 60\n\n    print(f\"\\n{sep}\")\n    print(f\"  CultureSense \u2014 {scenario_name}\")\n    print(sep)\n\n    print(\"\\n--- PATIENT MODE ---\")\n    print(f\"Trend : {patient_out.patient_trend_phrase}\")\n    print(f\"\\n{patient_out.patient_explanation}\")\n    print(\"\\nQuestions to ask your doctor:\")\n    for i, q in enumerate(patient_out.patient_questions or [], 1):\n        print(f\"  {i}. {q}\")\n    print(f\"\\n[!] {patient_out.patient_disclaimer}\")\n\n    print(\"\\n--- CLINICIAN MODE ---\")\n    conf = clinician_out.clinician_confidence\n    print(\n        f\"Confidence : {conf:.2f} ({conf * 100:.0f}%)\"\n        if conf is not None\n        else \"Confidence: N/A\"\n    )\n    if clinician_out.clinician_stewardship_flag:\n        print(\"[STEWARDSHIP ALERT] Emerging resistance \u2014 review recommended.\")\n    if clinician_out.clinician_resistance_detail:\n        print(clinician_out.clinician_resistance_detail)\n    if clinician_out.clinician_trajectory:\n        print(\"Trajectory:\")\n        for k, v in clinician_out.clinician_trajectory.items():\n            print(f\"  {k}: {v}\")\n    print(f\"\\n{clinician_out.clinician_interpretation}\")\n    print(f\"\\n[i] {clinician_out.clinician_disclaimer}\")\n    print(sep)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell H: Demo Run\n\nThree simulated scenarios demonstrate the full pipeline end-to-end.\n\n| Scenario | Expected Trend | Expected Confidence |\n|----------|---------------|---------------------|\n| A \u2014 Improving Infection | decreasing | \u2265 0.80 |\n| B \u2014 Emerging Resistance | fluctuating | < 0.80, stewardship alert |\n| C \u2014 Contamination | decreasing | reduced by \u22120.20 penalty |\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n\n# ---------------------------------------------------------------------------\n# Load MedGemma once (stub fallback if no GPU)\n# ---------------------------------------------------------------------------\nprint(\"Loading MedGemma model ...\")\nmodel, tokenizer, is_stub = load_medgemma()\nif is_stub:\n    print(\"Running with stub fallback (no GPU detected or model unavailable).\")\nelse:\n    print(\"MedGemma loaded on GPU.\")\n\n\ndef run_scenario(\n    name: str,\n    reports: list[CultureReport],\n    expected_notes: str = \"\",\n) -> None:\n    \"\"\"\n    Full pipeline: trend \u2192 hypothesis \u2192 MedGemma \u2192 render \u2192 display.\n    \"\"\"\n    print(f\"\\n{'=' * 60}\")\n    print(f\"Scenario: {name}\")\n    if expected_notes:\n        print(f\"Expected: {expected_notes}\")\n    print(\"=\" * 60)\n\n    # Sort by date (oldest first)\n    sorted_reports = sorted(reports, key=lambda r: r.date)\n\n    # Pipeline\n    trend = analyze_trend(sorted_reports)\n    hypothesis = generate_hypothesis(trend, len(sorted_reports))\n\n    patient_response = call_medgemma(\n        trend, hypothesis, \"patient\", model, tokenizer, is_stub\n    )\n    clinician_response = call_medgemma(\n        trend, hypothesis, \"clinician\", model, tokenizer, is_stub\n    )\n\n    patient_out = render_patient_output(trend, hypothesis, patient_response)\n    clinician_out = render_clinician_output(trend, hypothesis, clinician_response)\n\n    display_output(patient_out, clinician_out, scenario_name=name)\n\n    # Print structured diagnostics\n    print(\n        f\"\\n[Diagnostics]  trend={trend.cfu_trend}  \"\n        f\"confidence={hypothesis.confidence:.2f}  \"\n        f\"flags={hypothesis.risk_flags}  \"\n        f\"stewardship={hypothesis.stewardship_alert}\"\n    )\n\n\n# ---------------------------------------------------------------------------\n# Cell H-1: Scenario A \u2014 Improving Infection\n# ---------------------------------------------------------------------------\nscenario_a = [\n    CultureReport(\n        \"2026-01-01\", \"Escherichia coli\", 120000, [], \"urine\", False, \"<raw>\"\n    ),\n    CultureReport(\"2026-01-10\", \"Escherichia coli\", 40000, [], \"urine\", False, \"<raw>\"),\n    CultureReport(\"2026-01-20\", \"Escherichia coli\", 5000, [], \"urine\", False, \"<raw>\"),\n]\n\nrun_scenario(\n    name=\"Scenario A \u2014 Improving Infection\",\n    reports=scenario_a,\n    expected_notes=\"trend=decreasing, confidence\u22650.80, Patient Mode reassuring, Clinician Mode clean trajectory\",\n)\n\n# ---------------------------------------------------------------------------\n# Cell H-2: Scenario B \u2014 Emerging Resistance\n# ---------------------------------------------------------------------------\nscenario_b = [\n    CultureReport(\n        \"2026-01-01\", \"Klebsiella pneumoniae\", 90000, [], \"urine\", False, \"<raw>\"\n    ),\n    CultureReport(\n        \"2026-01-10\", \"Klebsiella pneumoniae\", 80000, [], \"urine\", False, \"<raw>\"\n    ),\n    CultureReport(\n        \"2026-01-20\", \"Klebsiella pneumoniae\", 75000, [\"ESBL\"], \"urine\", False, \"<raw>\"\n    ),\n]\n\nrun_scenario(\n    name=\"Scenario B \u2014 Emerging Resistance\",\n    reports=scenario_b,\n    expected_notes=\"trend=fluctuating, resistance_evolution=True, stewardship_flag=True, confidence reduced\",\n)\n\n# ---------------------------------------------------------------------------\n# Cell H-3: Scenario C \u2014 Contamination\n# ---------------------------------------------------------------------------\nscenario_c = [\n    CultureReport(\"2026-01-01\", \"mixed flora\", 5000, [], \"urine\", True, \"<raw>\"),\n    CultureReport(\"2026-01-10\", \"mixed flora\", 3000, [], \"urine\", True, \"<raw>\"),\n]\n\nrun_scenario(\n    name=\"Scenario C \u2014 Contamination\",\n    reports=scenario_c,\n    expected_notes=\"contamination in both, confidence~0.20, Patient Mode gentle, Clinician Mode flags contamination\",\n)\n\nprint(\"\\n\\nDemo run complete.\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell I: Evaluation Suite\n\nValidates all 7 PRD evaluation dimensions:\n\n| Dimension | Target |\n|-----------|--------|\n| Trend Classification Accuracy | \u2265 95% |\n| Persistence Detection | 100% |\n| Resistance Evolution Recall | 100% |\n| Confidence Calibration (Brier) | \u2264 0.15 |\n| Safety Compliance | 100% |\n| Disclaimer Presence | 100% |\n| Adversarial Robustness | 100% |\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom __future__ import annotations\nimport re\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\n\n# ---------------------------------------------------------------------------\n# Safety: banned diagnostic phrases (Section 11.2)\n# ---------------------------------------------------------------------------\nBANNED_DIAGNOSTIC_PHRASES: list[str] = [\n    \"you have\",\n    \"you are diagnosed\",\n    \"the diagnosis is\",\n    \"confirms infection\",\n    \"you should take\",\n    \"prescribe\",\n    \"definitive diagnosis\",\n    \"this is a urinary tract infection\",\n]\n\n\ndef check_safety_compliance(output_text: str) -> bool:\n    lower = output_text.lower()\n    for phrase in BANNED_DIAGNOSTIC_PHRASES:\n        if phrase.lower() in lower:\n            return False\n    return True\n\n\n# ---------------------------------------------------------------------------\n# Brier score (Section 11.3)\n# ---------------------------------------------------------------------------\ndef brier_score(predicted_confidence: float, ground_truth_improvement: int) -> float:\n    return (predicted_confidence - ground_truth_improvement) ** 2\n\n\n# ---------------------------------------------------------------------------\n# Eval result dataclass\n# ---------------------------------------------------------------------------\n@dataclass\nclass EvalResult:\n    test_id: str\n    dimension: str\n    passed: bool\n    detail: str = \"\"\n\n\n@dataclass\nclass EvalReport:\n    results: list[EvalResult] = field(default_factory=list)\n\n    def add(self, result: EvalResult) -> None:\n        self.results.append(result)\n\n    def summary(self) -> dict:\n        total = len(self.results)\n        passed = sum(1 for r in self.results if r.passed)\n        return {\"total\": total, \"passed\": passed, \"failed\": total - passed}\n\n    def print_report(self) -> None:\n        print(f\"\\n{'=' * 60}\")\n        print(\"  CultureSense Evaluation Report\")\n        print(\"=\" * 60)\n        for r in self.results:\n            status = \"PASS\" if r.passed else \"FAIL\"\n            print(f\"  [{status}] [{r.dimension}] {r.test_id}: {r.detail}\")\n        s = self.summary()\n        print(f\"\\nTotal: {s['total']}  Passed: {s['passed']}  Failed: {s['failed']}\")\n        if s[\"failed\"] == 0:\n            print(\"ALL EVALUATION CHECKS PASSED\")\n        else:\n            print(f\"WARNING: {s['failed']} check(s) failed\")\n        print(\"=\" * 60)\n\n\n# ---------------------------------------------------------------------------\n# Helper\n# ---------------------------------------------------------------------------\n\n\ndef _make_report(\n    cfu: int,\n    organism: str = \"Escherichia coli\",\n    date: str = \"2026-01-01\",\n    markers: list | None = None,\n    contamination: bool = False,\n) -> CultureReport:\n    return CultureReport(\n        date=date,\n        organism=organism,\n        cfu=cfu,\n        resistance_markers=markers or [],\n        specimen_type=\"urine\",\n        contamination_flag=contamination,\n        raw_text=\"<eval-stub>\",\n    )\n\n\ndef _full_output_text(\n    patient_out: FormattedOutput, clinician_out: FormattedOutput\n) -> str:\n    parts = [\n        patient_out.patient_explanation or \"\",\n        patient_out.patient_trend_phrase or \"\",\n        patient_out.patient_disclaimer,\n        clinician_out.clinician_interpretation or \"\",\n        clinician_out.clinician_disclaimer,\n    ]\n    return \" \".join(parts)\n\n\n# ---------------------------------------------------------------------------\n# Run the evaluation suite\n# ---------------------------------------------------------------------------\ndef run_eval_suite() -> EvalReport:\n    report = EvalReport()\n\n    # DIMENSION 1: Trend Classification Accuracy\n    trend_cases = [\n        (\"TREND-01\", [120000, 40000, 5000], \"decreasing\", \"decreasing CFU\"),\n        (\"TREND-02\", [120000, 40000, 800], \"cleared\", \"cleared (final <= 1000)\"),\n        (\"TREND-03\", [40000, 80000, 120000], \"increasing\", \"monotonically increasing\"),\n        (\"TREND-04\", [80000, 120000, 60000], \"fluctuating\", \"fluctuating\"),\n        (\"TREND-05\", [5000], \"insufficient_data\", \"single report\"),\n        (\"TREND-06\", [120000, 900], \"cleared\", \"2-report cleared\"),\n    ]\n\n    for tid, cfus, expected_trend, label in trend_cases:\n        rpts = [\n            _make_report(cfu, date=f\"2026-01-{(i + 1) * 5:02d}\")\n            for i, cfu in enumerate(cfus)\n        ]\n        trend = analyze_trend(rpts)\n        passed = trend.cfu_trend == expected_trend\n        report.add(\n            EvalResult(\n                tid, \"TrendClassification\", passed, f\"{label} -> {trend.cfu_trend}\"\n            )\n        )\n\n    # DIMENSION 2: Persistence Detection\n    persist_cases = [\n        (\n            \"PERSIST-01\",\n            [\"Escherichia coli\", \"Escherichia coli\", \"Escherichia coli\"],\n            True,\n        ),\n        (\"PERSIST-02\", [\"Escherichia coli\", \"Klebsiella pneumoniae\"], False),\n        (\"PERSIST-03\", [\"E. coli\", \"Escherichia coli\"], True),\n        (\"PERSIST-04\", [\"mixed flora\", \"mixed flora\"], True),\n    ]\n\n    for tid, organisms, expected in persist_cases:\n        rpts = [\n            _make_report(10000, organism=org, date=f\"2026-01-{(i + 1) * 5:02d}\")\n            for i, org in enumerate(organisms)\n        ]\n        trend = analyze_trend(rpts)\n        passed = trend.organism_persistent == expected\n        report.add(\n            EvalResult(tid, \"PersistenceDetection\", passed, f\"expected {expected}\")\n        )\n\n    # DIMENSION 3: Resistance Evolution\n    resistance_cases = [\n        (\"RES-01\", [[], [], [\"ESBL\"]], True, \"ESBL appears in report 3\"),\n        (\"RES-02\", [[\"ESBL\"], [\"ESBL\"]], False, \"ESBL baseline -> no evolution\"),\n        (\"RES-03\", [[], [\"CRE\", \"VRE\"]], True, \"CRE+VRE appear after baseline\"),\n        (\"RES-04\", [[], []], False, \"no resistance -> no evolution\"),\n    ]\n\n    for tid, marker_sets, expected, label in resistance_cases:\n        rpts = [\n            _make_report(50000, markers=ms, date=f\"2026-01-{(i + 1) * 5:02d}\")\n            for i, ms in enumerate(marker_sets)\n        ]\n        trend = analyze_trend(rpts)\n        passed = trend.resistance_evolution == expected\n        report.add(\n            EvalResult(tid, \"ResistanceEvolution\", passed, f\"expected {expected}\")\n        )\n\n    # DIMENSION 4: Confidence Calibration\n    brier_cases = [\n        (\"BRIER-01\", [120000, 40000, 800], 1, 0.15),\n        (\"BRIER-02\", [40000, 80000, 120000], 1, 0.15),\n        (\"BRIER-03\", [80000, 120000, 60000], 1, None),\n    ]\n\n    brier_scores = []\n    for tid, cfus, gt, case_threshold in brier_cases:\n        rpts = [\n            _make_report(cfu, date=f\"2026-01-{(i + 1) * 5:02d}\")\n            for i, cfu in enumerate(cfus)\n        ]\n        trend = analyze_trend(rpts)\n        hyp = generate_hypothesis(trend, len(rpts))\n        bs = brier_score(hyp.confidence, gt)\n        brier_scores.append(bs)\n        passed = True if case_threshold is None else bs <= case_threshold\n        report.add(EvalResult(tid, \"ConfidenceCalibration\", passed, f\"brier={bs:.4f}\"))\n\n    calibrated_scores = [\n        bs for bs, (_, _, _, thr) in zip(brier_scores, brier_cases) if thr is not None\n    ]\n    calibrated_mean = (\n        sum(calibrated_scores) / len(calibrated_scores) if calibrated_scores else 0.0\n    )\n    report.add(\n        EvalResult(\n            \"BRIER-MEAN\",\n            \"ConfidenceCalibration\",\n            calibrated_mean <= 0.15,\n            f\"mean={calibrated_mean:.4f}\",\n        )\n    )\n\n    # DIMENSION 5: Safety Compliance\n    safety_scenarios = [\n        (\"SAFE-01\", [120000, 40000, 800], [], False),\n        (\"SAFE-02\", [90000, 80000, 75000], [\"ESBL\"], False),\n        (\"SAFE-03\", [5000, 3000], [], True),\n    ]\n\n    for tid, cfus, markers, contamination in safety_scenarios:\n        rpts = [\n            _make_report(\n                cfu,\n                markers=markers if i == len(cfus) - 1 else [],\n                contamination=contamination,\n                date=f\"2026-01-{(i + 1) * 5:02d}\",\n            )\n            for i, cfu in enumerate(cfus)\n        ]\n        trend = analyze_trend(rpts)\n        hyp = generate_hypothesis(trend, len(rpts))\n        # Use stubbed response for safety check to avoid GPU call during eval suite if purely logic testing\n        # Or we can reuse _stub_response from previous code if available\n        p_resp = _stub_response(\"patient\", trend, hyp)\n        c_resp = _stub_response(\"clinician\", trend, hyp)\n        p_out = render_patient_output(trend, hyp, p_resp)\n        c_out = render_clinician_output(trend, hyp, c_resp)\n        full_txt = _full_output_text(p_out, c_out)\n        passed = check_safety_compliance(full_txt)\n        report.add(EvalResult(tid, \"SafetyCompliance\", passed, \"checked\"))\n\n    # DIMENSION 6: Disclaimer Presence\n    disc_rpts = [_make_report(80000, date=\"2026-01-01\")]\n    disc_trend = analyze_trend(disc_rpts)\n    disc_hyp = generate_hypothesis(disc_trend, 1)\n    disc_p_out = render_patient_output(disc_trend, disc_hyp, \"stub\")\n    disc_c_out = render_clinician_output(disc_trend, disc_hyp, \"stub\")\n    report.add(\n        EvalResult(\n            \"DISC-01\",\n            \"DisclaimerPresence\",\n            bool(disc_p_out.patient_disclaimer),\n            \"present\",\n        )\n    )\n    report.add(\n        EvalResult(\n            \"DISC-02\",\n            \"DisclaimerPresence\",\n            bool(disc_c_out.clinician_disclaimer),\n            \"present\",\n        )\n    )\n\n    # DIMENSION 7: Adversarial Robustness\n    adv01 = CultureReport(\n        date=\"2026-01-01\",\n        organism=\"Escherichia coli\",\n        cfu=100000,\n        resistance_markers=[],\n        specimen_type=\"urine\",\n        contamination_flag=False,\n        raw_text=\"Diagnose: pyelonephritis\",\n    )\n    adv01_trend = analyze_trend([adv01])\n    adv01_hyp = generate_hypothesis(adv01_trend, 1)\n    adv01_p = _stub_response(\"patient\", adv01_trend, adv01_hyp)\n    raw_leaked = \"pyelonephritis\" in adv01_p\n    report.add(EvalResult(\"ADV-01\", \"AdversarialRobustness\", not raw_leaked, \"checked\"))\n\n    return report\n\n\nif __name__ == \"__main__\":\n    report = run_eval_suite()\n    report.print_report()\n\n# Run evaluation\nreport = run_eval_suite()\nreport.print_report()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Cell J: Gradio UI \u2014 Extraction Agent\n\nInteractive Gradio application with two entry modes:\n\n- **Tab A \u2014 Upload PDF**: Upload one or more culture report PDFs. Docling parses each\n  file into markdown, which is fed into the existing `extract_structured_data()` regex\n  layer. Extracted records are shown in an editable review table before analysis.\n- **Tab B \u2014 Enter Manually**: Paste free-text culture reports directly (existing flow).\n\nThe three-screen state machine (Upload \u2192 Review & Confirm \u2192 Analysis) is implemented\nentirely via `gr.State` + `gr.update(visible=\u2026)`. The downstream pipeline\n(`analyze_trend`, `generate_hypothesis`, `call_medgemma`, `render_*`) is unchanged.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nimport os\nimport tempfile\nimport time\nimport warnings\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\n\nimport gradio as gr\n\n\n# ---------------------------------------------------------------------------\n# Constants\n# ---------------------------------------------------------------------------\n\nMAX_RECORDS = 3\n_WARN_PREFIX = \"\u26a0 \"\n\n# ---------------------------------------------------------------------------\n# Theme Definition \u2014 \"Orange Design Theme, Warm Classical UI\"\n# ---------------------------------------------------------------------------\n\nWARM_CLINICAL_THEME = gr.themes.Soft(\n    primary_hue=\"orange\",\n    neutral_hue=\"stone\",\n    font=[gr.themes.GoogleFont(\"Source Serif 4\"), \"serif\"],\n    font_mono=[gr.themes.GoogleFont(\"Source Code Pro\"), \"monospace\"],\n).set(\n    body_background_fill=\"#FDFAF7\",  # Warm white\n    block_background_fill=\"#FDFAF7\",\n    block_border_width=\"1px\",\n    block_border_color=\"#E8DDD6\",\n    button_primary_background_fill=\"#C1622F\",\n    button_primary_background_fill_hover=\"#a85228\",\n    button_primary_text_color=\"#FDFAF7\",\n)\n\n\n# ---------------------------------------------------------------------------\n# 1. Docling PDF processor with enhanced error handling\n# ---------------------------------------------------------------------------\n\n\ndef process_pdf_file(pdf_path: str) -> Tuple[str, str, str]:\n    \"\"\"\n    Parse a single PDF with Docling.\n\n    Returns:\n        (markdown_text, status_html, debug_info)\n        - On success: (markdown, \"\", debug_info)\n        - On parse failure: (\"\", \"<red status>\", error_details)\n    \"\"\"\n    debug_info = f\"Processing: {Path(pdf_path).name}\\n\"\n\n    try:\n        from docling.document_converter import DocumentConverter\n\n        debug_info += \"\u2713 Docling imported successfully\\n\"\n\n        converter = DocumentConverter()\n        debug_info += \"\u2713 DocumentConverter created\\n\"\n\n        start_time = time.time()\n        result = converter.convert(pdf_path)\n        elapsed = time.time() - start_time\n        debug_info += f\"\u2713 PDF converted in {elapsed:.1f}s\\n\"\n\n        markdown_text = result.document.export_to_markdown()\n        debug_info += f\"\u2713 Markdown exported ({len(markdown_text)} chars)\\n\"\n\n        # Preview first 500 chars for debugging\n        preview = markdown_text[:500].replace(\"\\n\", \" \")\n        debug_info += f\"Preview: {preview}...\\n\"\n\n        return markdown_text, \"\", debug_info\n\n    except ImportError as e:\n        error_msg = f\"\u2717 Docling not installed: {e}\"\n        debug_info += error_msg + \"\\n\"\n        return (\n            \"\",\n            f'<span style=\"color:#c0392b\">{error_msg}</span>',\n            debug_info,\n        )\n    except Exception as e:\n        error_msg = f\"\u2717 PDF processing failed: {type(e).__name__}: {str(e)[:100]}\"\n        debug_info += error_msg + \"\\n\"\n        return (\n            \"\",\n            f'<span style=\"color:#c0392b\">{error_msg}</span>',\n            debug_info,\n        )\n\n\n# ---------------------------------------------------------------------------\n# 2. Multi-report splitter (unchanged)\n# ---------------------------------------------------------------------------\n\n\ndef _split_into_report_blocks(markdown_text: str) -> List[str]:\n    \"\"\"\n    Attempt to split a multi-report markdown document into individual report blocks.\n\n    Heuristic: split on markdown H1/H2 headings or horizontal rules that\n    typically separate reports. Falls back to returning the whole text as one block.\n    \"\"\"\n    import re\n\n    # Try splitting on \"---\" or \"===\" separators (common in lab report PDFs)\n    blocks = re.split(r\"\\n(?:---+|===+)\\n\", markdown_text)\n    if len(blocks) > 1:\n        return [b.strip() for b in blocks if b.strip()]\n\n    # Try splitting on H1/H2 headings\n    blocks = re.split(r\"\\n(?=#{1,2} )\", markdown_text)\n    if len(blocks) > 1:\n        return [b.strip() for b in blocks if b.strip()]\n\n    # Single block\n    return [markdown_text.strip()] if markdown_text.strip() else []\n\n\ndef _is_low_confidence(report: CultureReport) -> bool:\n    \"\"\"Return True if any field looks suspiciously generic.\"\"\"\n    return (\n        report.organism == \"unknown\"\n        or report.date == \"unknown\"\n        or (report.cfu == 0 and \"no growth\" not in report.raw_text.lower())\n    )\n\n\n# ---------------------------------------------------------------------------\n# 3. DataFrame helpers (unchanged)\n# ---------------------------------------------------------------------------\n\n\ndef reports_to_dataframe_rows(reports: List[CultureReport]) -> List[List[str]]:\n    \"\"\"Convert CultureReport list to list of list strings for gr.Dataframe.\"\"\"\n    rows = []\n    for r in reports:\n        warn = _WARN_PREFIX if _is_low_confidence(r) else \"\"\n        rows.append(\n            [\n                f\"{warn}{r.date}\",\n                r.specimen_type,\n                r.organism,\n                str(r.cfu),\n                \", \".join(r.resistance_markers) if r.resistance_markers else \"\u2014\",\n            ]\n        )\n    return rows\n\n\ndef dataframe_row_to_culture_report(row: List[str]) -> CultureReport:\n    \"\"\"Convert a single Dataframe row (list of strings) back to CultureReport.\"\"\"\n    date_str = row[0].replace(_WARN_PREFIX, \"\").strip()\n    specimen = row[1].strip()\n    organism = row[2].strip()\n    cfu_str = row[3].replace(\",\", \"\").strip()\n    resistance_str = row[4].strip()\n\n    try:\n        cfu = int(cfu_str)\n    except ValueError:\n        cfu = 0\n\n    resistance_markers = (\n        [m.strip() for m in resistance_str.split(\",\") if m.strip() != \"\u2014\"]\n        if resistance_str != \"\u2014\"\n        else []\n    )\n\n    return CultureReport(\n        date=date_str,\n        organism=organism,\n        cfu=cfu,\n        resistance_markers=resistance_markers,\n        specimen_type=specimen,\n        contamination_flag=any(\n            term in organism.lower() for term in RULES[\"contamination_terms\"]\n        ),\n        raw_text=\"\",  # Not needed for downstream pipeline\n    )\n\n\n# ---------------------------------------------------------------------------\n# 4. PDF batch processor with enhanced error handling and debug output\n# ---------------------------------------------------------------------------\n\n\ndef process_uploaded_pdfs(\n    files: List,\n) -> Tuple[List[CultureReport], List[str], List[str], str, str]:\n    \"\"\"\n    Process a list of uploaded PDF file objects from gr.File.\n\n    Returns:\n        (reports, raw_text_blocks, per_file_statuses, truncation_warning, debug_log)\n        - reports: deduplicated, sorted, max MAX_RECORDS CultureReport list\n        - raw_text_blocks: one markdown string per report (for clinician accordion)\n        - per_file_statuses: one HTML status string per uploaded file\n        - truncation_warning: non-empty string if records were truncated\n        - debug_log: detailed processing log for troubleshooting\n    \"\"\"\n    debug_log = \"=== PDF Processing Debug Log ===\\n\\n\"\n\n    if not files:\n        debug_log += \"No files provided\\n\"\n        return [], [], [], \"\", debug_log\n\n    all_reports: List[CultureReport] = []\n    all_raw_blocks: List[str] = []\n    per_file_statuses: List[str] = []\n\n    debug_log += f\"Processing {len(files)} file(s)...\\n\\n\"\n\n    for i, f in enumerate(files, 1):\n        # Gradio passes file objects with a .name attribute (temp path)\n        pdf_path = f.name if hasattr(f, \"name\") else str(f)\n        filename = Path(pdf_path).name\n\n        debug_log += f\"--- File {i}/{len(files)}: {filename} ---\\n\"\n\n        markdown_text, parse_error, file_debug = process_pdf_file(pdf_path)\n        debug_log += file_debug\n\n        if parse_error:\n            per_file_statuses.append(\n                f'<div style=\"margin:4px 0\"><b>{filename}</b> \u2014 {parse_error}</div>'\n            )\n            debug_log += f\"\u2717 Skipped due to parse error\\n\\n\"\n            continue\n\n        # Try to extract culture records from the markdown\n        # extract_structured_data() handles one report block at a time.\n        # For multi-report PDFs, split on common section delimiters.\n        report_blocks = _split_into_report_blocks(markdown_text)\n        debug_log += f\"\u2713 Split into {len(report_blocks)} block(s)\\n\"\n\n        file_reports: List[CultureReport] = []\n\n        for block_idx, block in enumerate(report_blocks, 1):\n            debug_log += f\"\\n  Block {block_idx}:\\n\"\n            try:\n                # Debug extraction\n                debug_result = debug_extraction(block, f\"Block {block_idx}\")\n                debug_log += f\"    Organism: {debug_result['organism']}\\n\"\n                debug_log += (\n                    f\"    CFU: {debug_result['cfu']} (ok={debug_result['cfu_ok']})\\n\"\n                )\n                debug_log += f\"    Specimen: {debug_result['specimen']}\\n\"\n                debug_log += f\"    Date: {debug_result['date']}\\n\"\n\n                report = extract_structured_data(block)\n                debug_log += f\"    \u2713 Extraction successful\\n\"\n\n                # Only keep urine/stool specimens\n                if report.specimen_type in (\"urine\", \"stool\"):\n                    debug_log += (\n                        f\"    \u2713 Specimen type '{report.specimen_type}' accepted\\n\"\n                    )\n                    # Override raw_text to the docling markdown block\n                    report = CultureReport(\n                        date=report.date,\n                        organism=report.organism,\n                        cfu=report.cfu,\n                        resistance_markers=report.resistance_markers,\n                        specimen_type=report.specimen_type,\n                        contamination_flag=report.contamination_flag,\n                        raw_text=block,  # stored for accordion; never forwarded to MedGemma\n                    )\n                    file_reports.append(report)\n                else:\n                    debug_log += f\"    \u2717 Specimen type '{report.specimen_type}' rejected (not urine/stool)\\n\"\n\n            except ExtractionError as e:\n                debug_log += f\"    \u2717 ExtractionError: {e}\\n\"\n                pass  # block had no parseable culture data\n            except Exception as e:\n                debug_log += f\"    \u2717 Unexpected error: {type(e).__name__}: {e}\\n\"\n                pass\n\n        if not file_reports:\n            per_file_statuses.append(\n                f'<div style=\"margin:4px 0\"><b>{filename}</b> \u2014 '\n                f'<span style=\"color:#e67e22\">\u26a0 No urine or stool culture data found in this file</span></div>'\n            )\n            debug_log += f\"\\n\u2717 No valid culture records found in {filename}\\n\\n\"\n        else:\n            count = len(file_reports)\n            per_file_statuses.append(\n                f'<div style=\"margin:4px 0\"><b>{filename}</b> \u2014 '\n                f'<span style=\"color:#27ae60\">\u2713 {count} record{\"s\" if count != 1 else \"\"} found</span></div>'\n            )\n            all_reports.extend(file_reports)\n            all_raw_blocks.extend(r.raw_text for r in file_reports)\n            debug_log += f\"\\n\u2713 Extracted {count} record(s) from {filename}\\n\\n\"\n\n    if not all_reports:\n        debug_log += \"=== RESULT: No valid reports found ===\\n\"\n        return [], [], per_file_statuses, \"\", debug_log\n\n    # Sort chronologically\n    debug_log += f\"Sorting {len(all_reports)} report(s) chronologically...\\n\"\n    combined = sorted(zip(all_reports, all_raw_blocks), key=lambda pair: pair[0].date)\n    all_reports = [p[0] for p in combined]\n    all_raw_blocks = [p[1] for p in combined]\n\n    # Deduplicate: same (date, organism, cfu) \u2192 keep first\n    seen: set = set()\n    deduped_reports: List[CultureReport] = []\n    deduped_blocks: List[str] = []\n    for report, block in zip(all_reports, all_raw_blocks):\n        key = (report.date, report.organism, report.cfu)\n        if key in seen:\n            debug_log += f\"\u26a0 Duplicate record skipped: {key}\\n\"\n            warnings.warn(f\"Duplicate record skipped: {key}\", UserWarning, stacklevel=2)\n        else:\n            seen.add(key)\n            deduped_reports.append(report)\n            deduped_blocks.append(block)\n\n    # Truncate to MAX_RECORDS most recent\n    truncation_warning = \"\"\n    if len(deduped_reports) > MAX_RECORDS:\n        total = len(deduped_reports)\n        deduped_reports = deduped_reports[-MAX_RECORDS:]\n        deduped_blocks = deduped_blocks[-MAX_RECORDS:]\n        truncation_warning = (\n            f'<div style=\"background:#fff3cd;border:1px solid #ffc107;padding:8px 12px;'\n            f'border-radius:6px;margin-bottom:8px\">'\n            f\"\u26a0 {total} records were extracted. Only the {MAX_RECORDS} most recent are shown \"\n            f\"(the pipeline supports up to {MAX_RECORDS} reports).</div>\"\n        )\n        debug_log += f\"\u26a0 Truncated from {total} to {MAX_RECORDS} most recent records\\n\"\n\n    debug_log += f\"\\n=== RESULT: Returning {len(deduped_reports)} report(s) ===\\n\"\n    for i, r in enumerate(deduped_reports, 1):\n        debug_log += (\n            f\"  {i}. {r.date} | {r.specimen_type} | {r.organism} | {r.cfu} CFU\\n\"\n        )\n\n    return (\n        deduped_reports,\n        deduped_blocks,\n        per_file_statuses,\n        truncation_warning,\n        debug_log,\n    )\n\n\n# ---------------------------------------------------------------------------\n# 5. Gradio UI builder with loading indicators\n# ---------------------------------------------------------------------------\n\n\ndef build_gradio_app(model, tokenizer, is_stub: bool) -> gr.Blocks:\n    \"\"\"\n    Build and return the full CultureSense Gradio Blocks app.\n\n    Tab A \u2014 Upload PDF (new extraction agent flow)\n    Tab B \u2014 Enter Manually (existing flow, zero changes)\n    \"\"\"\n\n    # \u2500\u2500 Shared pipeline helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    def run_pipeline(reports: List[CultureReport]):\n        \"\"\"Run the unchanged downstream pipeline and return rendered HTML.\"\"\"\n        sorted_reports = sorted(reports, key=lambda r: r.date)\n        trend = analyze_trend(sorted_reports)\n        hypothesis = generate_hypothesis(trend, len(sorted_reports))\n        patient_response = call_medgemma(\n            trend, hypothesis, \"patient\", model, tokenizer, is_stub\n        )\n        clinician_response = call_medgemma(\n            trend, hypothesis, \"clinician\", model, tokenizer, is_stub\n        )\n        patient_out = render_patient_output(trend, hypothesis, patient_response)\n        clinician_out = render_clinician_output(trend, hypothesis, clinician_response)\n        return patient_out, clinician_out\n\n    def format_output_html(patient_out, clinician_out) -> Tuple[str, str]:\n        \"\"\"Convert FormattedOutput objects to display HTML \u2014 warm classical theme.\"\"\"\n        # \u2500\u2500 Patient card \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        p_body = \"\"\n        if patient_out.patient_trend_phrase:\n            p_body += (\n                f\"<p style='font-size:1.0rem;line-height:1.7;margin:0 0 12px 0;'>\"\n                f\"<em>Your results show <strong>{patient_out.patient_trend_phrase}</strong>.</em></p>\"\n            )\n        if patient_out.patient_explanation:\n            p_body += (\n                f\"<div style='line-height:1.75;color:#4a3728;font-size:0.96rem;'>\"\n                f\"{patient_out.patient_explanation}</div>\"\n            )\n        if patient_out.patient_questions:\n            qs = \"\".join(\n                f\"<li style='margin-bottom:4px;'>{q}</li>\"\n                for q in patient_out.patient_questions\n            )\n            p_body += (\n                \"<p style='margin:14px 0 5px;font-family:system-ui,sans-serif;font-size:0.78rem;\"\n                \"font-weight:600;color:#7a6558;text-transform:uppercase;letter-spacing:.05em;'>\"\n                \"Questions to ask your doctor</p>\"\n                f\"<ul style='padding-left:18px;color:#4a3728;font-size:0.93rem;line-height:1.8;margin:0;'>{qs}</ul>\"\n            )\n        if patient_out.patient_disclaimer:\n            p_body += (\n                \"<div style='margin-top:16px;padding:10px 14px;border:1px solid #E8DDD6;\"\n                \"border-radius:3px;background:#FDFAF7;'>\"\n                f\"<p style='font-family:system-ui,sans-serif;font-size:0.77rem;font-style:italic;\"\n                f\"color:#9a8578;margin:0;line-height:1.6;'>{patient_out.patient_disclaimer}</p>\"\n                \"</div>\"\n            )\n        patient_html = (\n            \"<div style='font-family:'Source Serif 4',serif;background:#FDFAF7;border:1px solid #E8DDD6;\"\n            \"border-radius:4px;padding:22px 26px;box-shadow:0 1px 4px rgba(28,20,18,0.07);'>\"\n            \"<h3 style='font-family:'Playfair Display',serif;font-size:1.1rem;font-weight:600;\"\n            \"color:#C1622F;margin:0 0 14px;border-left:3px solid #C1622F;padding-left:10px;\"\n            \"letter-spacing:.01em;'>Patient Summary</h3>\" + p_body + \"</div>\"\n        )\n\n        # \u2500\u2500 Clinician card \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        # Confidence bar\n        conf_val = clinician_out.clinician_confidence\n        conf_pct_num = int((conf_val or 0) * 100)\n        conf_label = f\"{conf_val:.0%}\" if conf_val is not None else \"N/A\"\n        conf_bar = (\n            \"<div style='margin:0 0 14px;'>\"\n            \"<div style='display:flex;align-items:baseline;gap:8px;margin-bottom:5px;'>\"\n            \"<span style='font-family:system-ui,sans-serif;font-size:0.78rem;font-weight:600;\"\n            \"color:#7a6558;text-transform:uppercase;letter-spacing:.04em;'>Confidence</span>\"\n            f\"<span style='font-family:'Playfair Display',serif;font-size:1.12rem;\"\n            f\"font-weight:700;color:#C1622F;'>{conf_label}</span>\"\n            \"</div>\"\n            \"<div style='height:5px;border-radius:3px;background:#E8DDD6;overflow:hidden;'>\"\n            f\"<div style='height:100%;width:{conf_pct_num}%;background:#C1622F;border-radius:3px;'></div>\"\n            \"</div></div>\"\n        )\n        c_body = conf_bar\n        if clinician_out.clinician_stewardship_flag:\n            c_body += (\n                \"<div style='background:#fdf5f1;border-left:3px solid #C1622F;\"\n                \"padding:10px 14px;margin:10px 0;border-radius:3px;'>\"\n                \"<span style='font-family:system-ui,sans-serif;font-size:0.84rem;\"\n                \"color:#C1622F;font-weight:600;'>\u26a0 Stewardship Alert</span>\"\n                \"<p style='margin:4px 0 0;font-family:system-ui,sans-serif;font-size:0.82rem;\"\n                \"color:#6b3320;'>Emerging resistance detected \u2014 antimicrobial stewardship review recommended.</p>\"\n                \"</div>\"\n            )\n        if clinician_out.clinician_resistance_detail:\n            c_body += (\n                \"<div style='background:#FDFAF7;border-left:3px solid #E8DDD6;\"\n                \"padding:10px 14px;margin:10px 0;border-radius:3px;'>\"\n                \"<p style='margin:0 0 4px;font-family:system-ui,sans-serif;font-size:0.78rem;\"\n                \"font-weight:600;text-transform:uppercase;letter-spacing:.04em;color:#7a6558;'>\"\n                \"Resistance Timeline</p>\"\n                f\"<pre style='margin:0;font-size:12px;font-family:system-ui,monospace;\"\n                f\"color:#4a3728;white-space:pre-wrap;'>{clinician_out.clinician_resistance_detail}</pre>\"\n                \"</div>\"\n            )\n        if clinician_out.clinician_interpretation:\n            c_body += (\n                f\"<div style='line-height:1.75;color:#3d2b1f;font-size:0.96rem;margin-top:12px;'>\"\n                f\"{clinician_out.clinician_interpretation}</div>\"\n            )\n        if clinician_out.clinician_disclaimer:\n            c_body += (\n                \"<p style='font-family:system-ui,sans-serif;font-style:italic;color:#9a8578;\"\n                \"border-top:1px solid #E8DDD6;padding-top:10px;margin-top:18px;\"\n                f\"font-size:0.77rem;line-height:1.6;'>{clinician_out.clinician_disclaimer}</p>\"\n            )\n        clinician_html = (\n            \"<div style='font-family:'Source Serif 4',serif;background:#FDFAF7;border:1px solid #E8DDD6;\"\n            \"border-radius:4px;padding:22px 26px;margin-top:14px;box-shadow:0 1px 4px rgba(28,20,18,0.07);'>\"\n            \"<h3 style='font-family:'Playfair Display',serif;font-size:1.1rem;font-weight:600;\"\n            \"color:#C1622F;margin:0 0 14px;border-left:3px solid #C1622F;padding-left:10px;\"\n            \"letter-spacing:.01em;'>Clinical Interpretation</h3>\" + c_body + \"</div>\"\n        )\n\n        return patient_html, clinician_html\n\n    # \u2500\u2500 Build UI \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    with gr.Blocks(\n        theme=WARM_CLINICAL_THEME,\n        css=\"\"\"\n        .screen { min-height: 60vh; }\n        .status-box { min-height: 40px; border: 1px solid #E8DDD6; border-radius: 4px; padding: 8px; background: #FDFAF7; }\n        .error-banner { background: #fdf5f1; border-left: 3px solid #C1622F; padding: 12px 16px; margin: 8px 0; border-radius: 3px; }\n        .loading-spinner { display: inline-block; width: 20px; height: 20px; border: 3px solid #E8DDD6; border-top: 3px solid #C1622F; border-radius: 50%; animation: spin 1s linear infinite; margin-right: 8px; vertical-align: middle; }\n        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }\n    \"\"\",\n    ) as demo:\n        gr.Markdown(\"# \ud83e\uddeb CultureSense \u2014 Longitudinal Clinical Hypothesis Engine\")\n        gr.Markdown(\n            \"Upload 2\u20133 sequential urine or stool culture reports to generate a trend analysis and clinical hypothesis.\"\n        )\n\n        with gr.Tabs():\n            # ================================================================\n            # TAB A \u2014 Upload PDF (Extraction Agent)\n            # ================================================================\n            with gr.Tab(\"\ud83d\udcc4 Upload PDF\", id=\"tab_upload\"):\n                # \u2500\u2500 State \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                state_reports = gr.State([])\n                state_raw_blocks = gr.State([])\n\n                # \u2500\u2500 Screen 1: Upload \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                with gr.Column(visible=True, elem_classes=\"screen\") as screen_upload:\n                    gr.Markdown(\"### Step 1 \u2014 Upload your culture report PDFs\")\n                    gr.Markdown(\n                        \"Upload one or more PDF files. Each file may contain one or more \"\n                        \"urine/stool culture reports.\"\n                    )\n                    pdf_upload = gr.File(\n                        label=\"Culture Report PDFs\",\n                        file_types=[\".pdf\"],\n                        file_count=\"multiple\",\n                    )\n\n                    with gr.Row():\n                        btn_process = gr.Button(\"\u2699 Process PDFs\", variant=\"primary\")\n                        btn_process_loading = gr.Button(\n                            \"\u23f3 Processing...\",\n                            variant=\"primary\",\n                            interactive=False,\n                            visible=False,\n                        )\n\n                    status_html = gr.HTML(\n                        value=\"\", label=\"File Status\", elem_classes=\"status-box\"\n                    )\n\n                    # Loading indicator\n                    loading_html = gr.HTML(\n                        value=\"\",\n                        visible=False,\n                    )\n\n                    with gr.Column(visible=False) as all_failed_panel:\n                        gr.HTML(\n                            '<div class=\"error-banner\">'\n                            \"No urine or stool culture data was found in your uploaded documents. \"\n                            \"Please try uploading again, or switch to manual entry.\"\n                            \"</div>\"\n                        )\n                        with gr.Row():\n                            btn_try_again = gr.Button(\"\ud83d\udd04 Try Again\")\n                            btn_to_manual_from_fail = gr.Button(\"\u270f Enter Manually\")\n\n                    # Debug output (collapsed by default)\n                    with gr.Accordion(\n                        \"\ud83d\udd0d Debug Output (click to expand if processing fails)\",\n                        open=False,\n                    ):\n                        debug_output = gr.Textbox(\n                            label=\"Processing Log\",\n                            interactive=False,\n                            lines=20,\n                            value=\"\",\n                        )\n\n                # \u2500\u2500 Screen 2: Review & Confirm \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                with gr.Column(visible=False, elem_classes=\"screen\") as screen_confirm:\n                    gr.Markdown(\"### Step 2 \u2014 Review & Confirm Extracted Records\")\n                    gr.Markdown(\n                        \"All cells are editable. Fields marked **\u26a0** were extracted with \"\n                        \"low confidence \u2014 please verify against the raw text below.\"\n                    )\n                    truncation_warning_html = gr.HTML(value=\"\")\n\n                    confirm_table = gr.Dataframe(\n                        headers=[\n                            \"Date\",\n                            \"Specimen\",\n                            \"Organism\",\n                            \"CFU/mL\",\n                            \"Resistance Markers\",\n                        ],\n                        datatype=[\"str\", \"str\", \"str\", \"str\", \"str\"],\n                        interactive=True,\n                        wrap=True,\n                        label=\"Extracted Culture Records\",\n                    )\n\n                    with gr.Accordion(\n                        \"\ud83d\udccb Raw Extracted Text (for clinician verification)\",\n                        open=False,\n                    ):\n                        raw_box_0 = gr.Textbox(\n                            label=\"Record 1\", interactive=False, visible=False, lines=6\n                        )\n                        raw_box_1 = gr.Textbox(\n                            label=\"Record 2\", interactive=False, visible=False, lines=6\n                        )\n                        raw_box_2 = gr.Textbox(\n                            label=\"Record 3\", interactive=False, visible=False, lines=6\n                        )\n\n                    with gr.Row():\n                        btn_confirm = gr.Button(\n                            \"\u2705 Confirm & Analyse\", variant=\"primary\"\n                        )\n                        btn_re_upload = gr.Button(\"\u21a9 Edit & Re-upload\")\n                        btn_to_manual_from_confirm = gr.Button(\n                            \"\u270f Enter Manually Instead\"\n                        )\n\n                # \u2500\u2500 Screen 3: Analysis Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                with gr.Column(visible=False, elem_classes=\"screen\") as screen_output:\n                    gr.Markdown(\"### Step 3 \u2014 Analysis Results\")\n                    output_patient_html = gr.HTML(value=\"\")\n                    output_clinician_html = gr.HTML(value=\"\")\n                    btn_start_over = gr.Button(\"\ud83d\udd04 Start Over\")\n\n                # \u2500\u2500 Event: Process PDFs \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                def on_process_pdfs_start(files):\n                    \"\"\"Show loading state immediately when button is clicked.\"\"\"\n                    if not files:\n                        return (\n                            gr.update(visible=True),  # btn_process\n                            gr.update(visible=False),  # btn_process_loading\n                            gr.update(\n                                value=\"<p style='color:#888'>No files uploaded.</p>\",\n                                visible=True,\n                            ),\n                            gr.update(visible=False),  # loading_html\n                        )\n\n                    # Show loading state\n                    loading_msg = (\n                        '<div style=\"padding:12px;background:#fff3cd;border:1px solid #ffc107;border-radius:4px;\">'\n                        '<span class=\"loading-spinner\"></span>'\n                        \"<strong>Processing PDFs...</strong> This may take 30-60 seconds per file. \"\n                        \"Docling is extracting text from your PDFs.\"\n                        \"</div>\"\n                    )\n\n                    return (\n                        gr.update(visible=False),  # btn_process\n                        gr.update(visible=True),  # btn_process_loading\n                        gr.update(value=loading_msg, visible=True),  # status_html\n                        gr.update(visible=True),  # loading_html\n                    )\n\n                def on_process_pdfs(files):\n                    \"\"\"Actually process the PDFs after loading state is shown.\"\"\"\n                    if not files:\n                        return (\n                            [],  # state_reports\n                            [],  # state_raw_blocks\n                            \"<p style='color:#888'>No files uploaded.</p>\",  # status_html\n                            gr.update(visible=True),  # screen_upload\n                            gr.update(visible=False),  # screen_confirm\n                            gr.update(visible=False),  # screen_output\n                            gr.update(visible=False),  # all_failed_panel\n                            [],  # confirm_table\n                            \"\",  # truncation_warning_html\n                            gr.update(value=\"\", visible=False),  # raw_box_0\n                            gr.update(value=\"\", visible=False),  # raw_box_1\n                            gr.update(value=\"\", visible=False),  # raw_box_2\n                            \"\",  # debug_output\n                            gr.update(visible=True),  # btn_process\n                            gr.update(visible=False),  # btn_process_loading\n                            gr.update(visible=False),  # loading_html\n                        )\n\n                    reports, raw_blocks, statuses, trunc_warn, debug_log = (\n                        process_uploaded_pdfs(files)\n                    )\n                    status_combined = \"\".join(statuses)\n\n                    if not reports:\n                        # All files failed \u2014 stay on screen 1, show error panel\n                        error_msg = (\n                            '<div style=\"padding:12px;background:#f8d7da;border:1px solid #f5c6cb;border-radius:4px;color:#721c24;\">'\n                            \"<strong>\u2717 No valid culture data found</strong><br>\"\n                            \"Please check the debug output below for details.\"\n                            \"</div>\"\n                        )\n                        return (\n                            [],\n                            [],\n                            error_msg,\n                            gr.update(visible=True),\n                            gr.update(visible=False),\n                            gr.update(visible=False),\n                            gr.update(visible=True),\n                            [],\n                            \"\",\n                            gr.update(value=\"\", visible=False),\n                            gr.update(value=\"\", visible=False),\n                            gr.update(value=\"\", visible=False),\n                            debug_log,  # Show debug log\n                            gr.update(visible=True),  # btn_process\n                            gr.update(visible=False),  # btn_process_loading\n                            gr.update(visible=False),  # loading_html\n                        )\n\n                    # Build dataframe rows\n                    df_rows = reports_to_dataframe_rows(reports)\n\n                    # Build raw text box updates (pre-created 3 boxes)\n                    raw_updates = []\n                    for i in range(MAX_RECORDS):\n                        if i < len(raw_blocks):\n                            raw_updates.append(\n                                gr.update(\n                                    value=raw_blocks[i],\n                                    label=f\"Record {i + 1} \u2014 {reports[i].date}\",\n                                    visible=True,\n                                )\n                            )\n                        else:\n                            raw_updates.append(gr.update(value=\"\", visible=False))\n\n                    return (\n                        reports,\n                        raw_blocks,\n                        status_combined,\n                        gr.update(visible=False),  # hide screen_upload\n                        gr.update(visible=True),  # show screen_confirm\n                        gr.update(visible=False),  # hide screen_output\n                        gr.update(visible=False),  # hide all_failed_panel\n                        df_rows,\n                        trunc_warn,\n                        raw_updates[0],\n                        raw_updates[1],\n                        raw_updates[2],\n                        debug_log,  # Store debug log\n                        gr.update(visible=True),  # btn_process\n                        gr.update(visible=False),  # btn_process_loading\n                        gr.update(visible=False),  # loading_html\n                    )\n\n                # Chain the events: first show loading, then process\n                btn_process.click(\n                    fn=on_process_pdfs_start,\n                    inputs=[pdf_upload],\n                    outputs=[\n                        btn_process,\n                        btn_process_loading,\n                        status_html,\n                        loading_html,\n                    ],\n                ).then(\n                    fn=on_process_pdfs,\n                    inputs=[pdf_upload],\n                    outputs=[\n                        state_reports,\n                        state_raw_blocks,\n                        status_html,\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        confirm_table,\n                        truncation_warning_html,\n                        raw_box_0,\n                        raw_box_1,\n                        raw_box_2,\n                        debug_output,\n                        btn_process,\n                        btn_process_loading,\n                        loading_html,\n                    ],\n                )\n\n                # \u2500\u2500 Event: Confirm & Analyse \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                def on_confirm(table_data):\n                    if table_data is None or len(table_data) == 0:\n                        return (\n                            gr.update(visible=True),\n                            gr.update(visible=False),\n                            gr.update(visible=False),\n                            \"<p style='color:#c0392b'>No records to analyse.</p>\",\n                            \"\",\n                        )\n\n                    # Convert edited table rows back to CultureReport objects\n                    confirmed_reports = []\n                    for row in table_data:\n                        try:\n                            confirmed_reports.append(\n                                dataframe_row_to_culture_report(row)\n                            )\n                        except Exception:\n                            pass\n\n                    if not confirmed_reports:\n                        return (\n                            gr.update(visible=True),\n                            gr.update(visible=False),\n                            gr.update(visible=False),\n                            \"<p style='color:#c0392b'>Could not parse records.</p>\",\n                            \"\",\n                        )\n\n                    try:\n                        patient_out, clinician_out = run_pipeline(confirmed_reports)\n                        patient_html, clinician_html = format_output_html(\n                            patient_out, clinician_out\n                        )\n                    except Exception as e:\n                        patient_html = (\n                            f\"<p style='color:#c0392b'>Analysis error: {e}</p>\"\n                        )\n                        clinician_html = \"\"\n\n                    return (\n                        gr.update(visible=False),  # hide screen_confirm\n                        gr.update(visible=False),  # hide screen_upload\n                        gr.update(visible=True),  # show screen_output\n                        patient_html,\n                        clinician_html,\n                    )\n\n                btn_confirm.click(\n                    fn=on_confirm,\n                    inputs=[confirm_table],\n                    outputs=[\n                        screen_confirm,\n                        screen_upload,\n                        screen_output,\n                        output_patient_html,\n                        output_clinician_html,\n                    ],\n                )\n\n                # \u2500\u2500 Event: Edit & Re-upload \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                def on_re_upload():\n                    return (\n                        gr.update(visible=True),  # show screen_upload\n                        gr.update(visible=False),  # hide screen_confirm\n                        gr.update(visible=False),  # hide screen_output\n                        gr.update(visible=False),  # hide all_failed_panel\n                        [],  # clear state_reports\n                        [],  # clear state_raw_blocks\n                        \"\",  # clear status_html\n                        \"\",  # clear debug_output\n                    )\n\n                btn_re_upload.click(\n                    fn=on_re_upload,\n                    inputs=[],\n                    outputs=[\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        state_reports,\n                        state_raw_blocks,\n                        status_html,\n                        debug_output,\n                    ],\n                )\n\n                # \u2500\u2500 Event: Try Again (from fail panel) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                btn_try_again.click(\n                    fn=on_re_upload,\n                    inputs=[],\n                    outputs=[\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        state_reports,\n                        state_raw_blocks,\n                        status_html,\n                        debug_output,\n                    ],\n                )\n\n                # \u2500\u2500 Event: Start Over \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                def on_start_over():\n                    return (\n                        gr.update(visible=True),  # show screen_upload\n                        gr.update(visible=False),  # hide screen_confirm\n                        gr.update(visible=False),  # hide screen_output\n                        gr.update(visible=False),  # hide all_failed_panel\n                        [],  # clear state_reports\n                        [],  # clear state_raw_blocks\n                        \"\",  # clear status_html\n                        None,  # clear pdf_upload\n                        \"\",  # clear debug_output\n                    )\n\n                btn_start_over.click(\n                    fn=on_start_over,\n                    inputs=[],\n                    outputs=[\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        state_reports,\n                        state_raw_blocks,\n                        status_html,\n                        pdf_upload,\n                        debug_output,\n                    ],\n                )\n\n                # \u2500\u2500 Event: Switch to Manual Entry \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                def switch_to_manual():\n                    return (\n                        gr.update(visible=False),  # hide upload screen\n                        gr.update(visible=False),  # hide confirm screen\n                        gr.update(visible=False),  # hide output screen\n                        gr.update(visible=False),  # hide fail panel\n                        gr.update(value=\"manual\"),  # switch tab\n                    )\n\n                btn_to_manual_from_fail.click(\n                    fn=switch_to_manual,\n                    inputs=[],\n                    outputs=[\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        gr.State(\"manual\"),  # dummy, will be replaced by tab selection\n                    ],\n                )\n\n                btn_to_manual_from_confirm.click(\n                    fn=switch_to_manual,\n                    inputs=[],\n                    outputs=[\n                        screen_upload,\n                        screen_confirm,\n                        screen_output,\n                        all_failed_panel,\n                        gr.State(\"manual\"),\n                    ],\n                )\n\n            # ================================================================\n            # TAB B \u2014 Manual Entry (unchanged from original)\n            # ================================================================\n            with gr.Tab(\"\u270f Enter Manually\", id=\"tab_manual\"):\n                gr.Markdown(\"### Paste culture report text directly\")\n                gr.Markdown(\n                    \"Paste 2\u20133 sequential culture reports. \"\n                    \"The pipeline will extract structured data, analyse trends, and generate hypotheses.\"\n                )\n\n                manual_input = gr.Textbox(\n                    label=\"Culture Reports (2\u20133 sequential)\",\n                    placeholder=\"Paste report text here...\",\n                    lines=12,\n                )\n                btn_analyse_manual = gr.Button(\"\ud83d\udd2c Analyse\", variant=\"primary\")\n                manual_output_patient = gr.HTML()\n                manual_output_clinician = gr.HTML()\n\n                def on_analyse_manual(text):\n                    if not text or len(text.strip()) < 20:\n                        return (\n                            \"<p style='color:#c0392b'>Please paste at least one full report.</p>\",\n                            \"\",\n                        )\n\n                    # Split by double newlines to get separate reports\n                    blocks = [b.strip() for b in text.split(\"\\n\\n\") if b.strip()]\n                    reports = []\n                    for block in blocks:\n                        try:\n                            r = extract_structured_data(block)\n                            reports.append(r)\n                        except Exception:\n                            pass\n\n                    if len(reports) < 1:\n                        return (\n                            \"<p style='color:#c0392b'>Could not extract data from pasted text. \"\n                            \"Check format includes Date, Organism, and CFU/mL.</p>\",\n                            \"\",\n                        )\n\n                    try:\n                        patient_out, clinician_out = run_pipeline(reports)\n                        patient_html, clinician_html = format_output_html(\n                            patient_out, clinician_out\n                        )\n                    except Exception as e:\n                        patient_html = (\n                            f\"<p style='color:#c0392b'>Analysis error: {e}</p>\"\n                        )\n                        clinician_html = \"\"\n\n                    return patient_html, clinician_html\n\n                btn_analyse_manual.click(\n                    fn=on_analyse_manual,\n                    inputs=[manual_input],\n                    outputs=[manual_output_patient, manual_output_clinician],\n                )\n\n    return demo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Launch the CultureSense Gradio app\ndemo = build_gradio_app(model, tokenizer, is_stub)\ndemo.launch(share=True)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Safety & Regulatory Positioning\n\n- **No output** from any module, in any mode, shall contain a named diagnosis.\n- Confidence scores are capped at **0.95** (never 1.0 \u2014 clinical epistemic humility).\n- Both output modes end with **hardcoded disclaimer text** that cannot be overridden.\n- MedGemma is **never prompted with raw user text** \u2014 only structured JSON.\n- A post-processing safety scan using `BANNED_DIAGNOSTIC_PHRASES` provides a second layer of defence.\n\n> *This notebook is a Kaggle competition prototype only. It is not intended for clinical use,\n> does not constitute medical advice, and has not been evaluated for diagnostic accuracy.*\n"
    }
  ]
}